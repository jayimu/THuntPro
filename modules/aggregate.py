import re
import json
import socket
import requests
import os
import shutil
import glob
import time
import functools
import shutil
from typing import Dict, Any, List, Tuple, Optional
import concurrent.futures
from .threatbook import query_threatbook
from .abuseipdb import AbuseIPDBClient
from datetime import datetime, timedelta

# é¢„æœŸçš„æƒ…æŠ¥æºåˆ—è¡¨
EXPECTED_SOURCES = [
    "VirusTotal", "MalwareBazaar", "ThreatFox", "URLHaus", "AlienVault", 
    "InQuest", "AbuseIPDB", "HybridAnalysis", "Triage", "ThreatBook", "Malshare"
]

def get_terminal_width() -> int:
    """è·å–ç»ˆç«¯å®½åº¦ï¼Œç”¨äºå“åº”å¼å¸ƒå±€"""
    try:
        return shutil.get_terminal_size().columns
    except Exception:
        return 120  # é»˜è®¤å®½åº¦


def format_multi_column(items: List[str], label_width: int = 18, min_col_width: int = 30) -> str:
    """å°†é¡¹ç›®åˆ—è¡¨æ ¼å¼åŒ–ä¸ºå¤šåˆ—æ˜¾ç¤º"""
    if not items:
        return ""
    
    terminal_width = get_terminal_width()
    available_width = terminal_width - label_width - 3  # å‡å»æ ‡ç­¾å®½åº¦å’Œåˆ†éš”ç¬¦
    
    # è®¡ç®—åˆ—æ•°
    cols = max(1, min(3, available_width // min_col_width))
    if cols == 1:
        return ", ".join(items)
    
    # è®¡ç®—æ¯åˆ—å®½åº¦
    col_width = available_width // cols
    
    lines = []
    for i in range(0, len(items), cols):
        row_items = items[i:i+cols]
        # ç¡®ä¿æ¯åˆ—ä¸è¶…è¿‡è®¡ç®—å®½åº¦
        formatted_items = []
        for item in row_items:
            if len(item) > col_width - 2:
                formatted_items.append(item[:col_width-5] + "...")
            else:
                formatted_items.append(item)
        
        # å¡«å……åˆ°ç›¸åŒå®½åº¦
        padded_items = [item.ljust(col_width-2) for item in formatted_items]
        lines.append("  ".join(padded_items))
    
    return "\n".join(lines)


# å†…å­˜ç¼“å­˜è£…é¥°å™¨
@functools.lru_cache(maxsize=128)
def get_cached_data_memory(indicator: str, engine_name: str) -> Optional[Dict[str, Any]]:
    """å†…å­˜ç¼“å­˜ï¼šæ£€æŸ¥æ–‡ä»¶ç¼“å­˜å¹¶è¿”å›æ•°æ®ï¼Œä½¿ç”¨LRUç¼“å­˜é¿å…é‡å¤æ–‡ä»¶I/O"""
    return check_cache_and_load(indicator, engine_name)


def clear_tmp_folder() -> None:
    """æ¸…ç©º tmp æ–‡ä»¶å¤¹"""
    try:
        tmp_dir = os.path.join(os.path.dirname(os.path.dirname(__file__)), "tmp")
        if os.path.exists(tmp_dir):
            for file in os.listdir(tmp_dir):
                file_path = os.path.join(tmp_dir, file)
                if os.path.isfile(file_path):
                    os.remove(file_path)
    except Exception:
        pass  # å¿½ç•¥æ¸…ç†é”™è¯¯


def save_json_data(indicator: str, engine_name: str, data: Dict[str, Any]) -> None:
    """ä¿å­˜å„å¼•æ“å®Œæ•´ JSON æ•°æ®åˆ° modules/tmpã€‚
    - é»˜è®¤ï¼š{engine}_{indicator}_{timestamp}.jsonï¼ˆä»…ä¿ç•™æœ€æ–°ä¸€ä»½ï¼‰ã€‚
    - ç‰¹ä¾‹ï¼šHybridAnalysis ä¸ MalwareBazaar ä½¿ç”¨å›ºå®šå‘½åï¼š
      HybridAnalysis+<hash>.json, MalwareBazaar+<hash>.jsonã€‚
    - è¿‡æœŸé€»è¾‘é€šè¿‡ mtime ä¸ clear_old_cache å®ç°ã€‚
    """
    try:
        # åˆ›å»ºåŒ…ç›®å½•ä¸‹çš„ tmp ç¼“å­˜æ–‡ä»¶å¤¹
        tmp_dir = os.path.join(os.path.dirname(os.path.dirname(__file__)), "tmp")
        if not os.path.exists(tmp_dir):
            os.makedirs(tmp_dir)
        
        # å¯¹ indicator è¿›è¡Œå®‰å…¨å¤„ç†ï¼Œç§»é™¤ç‰¹æ®Šå­—ç¬¦
        safe_indicator = re.sub(r'[^\w\-\.]', '_', indicator)
        # é™åˆ¶é•¿åº¦ï¼Œé¿å…æ–‡ä»¶åè¿‡é•¿
        safe_indicator = safe_indicator[:50]
        
        eng_lower = (engine_name or '').lower()
        # ç‰¹ä¾‹å›ºå®šå‘½åï¼šè¦†ç›–å†™
        if eng_lower == 'hybrid':
            filename = f"HybridAnalysis+{safe_indicator}.json"
            filepath = os.path.join(tmp_dir, filename)
            try:
                if os.path.exists(filepath):
                    os.remove(filepath)
            except Exception:
                pass
        elif eng_lower == 'bazaar':
            filename = f"MalwareBazaar+{safe_indicator}.json"
            filepath = os.path.join(tmp_dir, filename)
            try:
                if os.path.exists(filepath):
                    os.remove(filepath)
            except Exception:
                pass
        else:
            # æ–‡ä»¶åï¼šå¼•æ“å_å®‰å…¨æŒ‡æ ‡_æ—¶é—´æˆ³.jsonï¼Œä»…ä¿ç•™ä¸€ä¸ªæœ€æ–°æ–‡ä»¶
            filename = f"{eng_lower}_{safe_indicator}_{int(time.time())}.json"
            filepath = os.path.join(tmp_dir, filename)
            # å…ˆæ¸…ç†åŒå‰ç¼€æ—§æ–‡ä»¶ï¼šä»…ä¿ç•™ä¸€ä¸ªæœ€æ–°æ–‡ä»¶
            try:
                prefix_pattern = os.path.join(tmp_dir, f"{eng_lower}_{safe_indicator}_*.json")
                old_files = sorted(glob.glob(prefix_pattern), key=os.path.getmtime, reverse=True)
                for old in old_files[1:]:
                    try:
                        os.remove(old)
                    except Exception:
                        pass
            except Exception:
                pass

        # ä¿å­˜ JSON æ•°æ®
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
            
    except Exception as e:
        print(f"ä¿å­˜ JSON æ•°æ®å¤±è´¥: {e}")


def _ensure_url_tmp_dir() -> str:
    """ç¡®ä¿åŒ…ç›®å½•ä¸‹ url_tmp å­˜åœ¨ï¼ˆç”¨äº URL ç±»ç»“æœç¼“å­˜ï¼‰ã€‚"""
    try:
        base_dir = os.path.join(os.path.dirname(os.path.dirname(__file__)), "url_tmp")
        if not os.path.exists(base_dir):
            os.makedirs(base_dir)
        return base_dir
    except Exception:
        return os.path.join(os.path.dirname(os.path.dirname(__file__)), "url_tmp")


def save_url_json(indicator: str, engine_name: str, data: Dict[str, Any]) -> None:
    """å°† URL/åŸŸåæŸ¥è¯¢ JSON ä¿å­˜è‡³åŒ…ç›®å½•ä¸‹ url_tmpï¼ˆç¨³å®šæ–‡ä»¶åï¼Œæ— æ—¶é—´æˆ³ï¼‰ã€‚"""
    try:
        out_dir = _ensure_url_tmp_dir()
        safe_indicator = re.sub(r'[^\w\-\.]', '_', indicator)[:80]
        filepath = os.path.join(out_dir, f"{engine_name.lower()}_{safe_indicator}.json")
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
    except Exception:
        pass

def check_cache_and_load(indicator: str, engine_name: str) -> Optional[Dict[str, Any]]:
    """æ£€æŸ¥ç¼“å­˜æ˜¯å¦åœ¨ä¸€ä¸ªæœˆå†…ï¼Œå¦‚æœ‰æ•ˆåˆ™åŠ è½½æœ€æ–°æ–‡ä»¶ï¼›å¦åˆ™è¿”å› Noneã€‚
    - ç‰¹ä¾‹ä¼˜å…ˆï¼šHybridAnalysis+<hash>.json, MalwareBazaar+<hash>.jsonã€‚
    - å…¶æ¬¡ï¼š{engine}_{indicator}_{timestamp}.json å–æœ€æ–°ã€‚
    """
    try:
        tmp_dir = os.path.join(os.path.dirname(os.path.dirname(__file__)), "tmp")
        if not os.path.exists(tmp_dir):
            return None
        
        safe_indicator = re.sub(r'[^\w\-\.]', '_', indicator)[:50]
        eng_lower = (engine_name or '').lower()
        candidates: List[str] = []
        # ç‰¹ä¾‹å›ºå®šå‘½åä¼˜å…ˆ
        if eng_lower == 'hybrid':
            candidates.append(os.path.join(tmp_dir, f"HybridAnalysis+{safe_indicator}.json"))
        elif eng_lower == 'bazaar':
            candidates.append(os.path.join(tmp_dir, f"MalwareBazaar+{safe_indicator}.json"))
        # æ–°å‘½åï¼ˆå¸¦æ—¶é—´æˆ³ï¼‰ï¼šé€‰æ‹©åŒå‰ç¼€çš„æœ€æ–°æ–‡ä»¶
        try:
            pattern = os.path.join(tmp_dir, f"{eng_lower}_{safe_indicator}_*.json")
            stamped_files = glob.glob(pattern)
            if stamped_files:
                latest = max(stamped_files, key=os.path.getmtime)
                candidates.append(latest)
        except Exception:
            pass

        for fp in candidates:
            if not os.path.isfile(fp):
                continue
            try:
                file_time = datetime.fromtimestamp(os.path.getmtime(fp))
                if datetime.now() - file_time <= timedelta(days=30):
                    with open(fp, 'r', encoding='utf-8') as f:
                        return json.load(f)
            except Exception:
                continue
        return None
            
    except Exception:
        return None
    
    return None


def clear_old_cache() -> None:
    """æ¸…ç†è¶…è¿‡ä¸€ä¸ªæœˆçš„æ—§ç¼“å­˜æ–‡ä»¶ï¼ˆæŒ‰ mtime åˆ¤æ–­ï¼‰ã€‚"""
    try:
        tmp_dir = os.path.join(os.path.dirname(os.path.dirname(__file__)), "tmp")
        if not os.path.exists(tmp_dir):
            return
        
        now = datetime.now()
        cutoff_time = now - timedelta(days=30)
        
        for file_path in glob.glob(os.path.join(tmp_dir, "*.json")):
            try:
                mtime = datetime.fromtimestamp(os.path.getmtime(file_path))
                if mtime < cutoff_time:
                        os.remove(file_path)
            except (OSError, ValueError):
                continue
                
    except Exception as e:
        print(f"æ¸…ç†æ—§ç¼“å­˜å¤±è´¥: {e}")


def clear_tmp_folder() -> None:
    """æ¸…ç†è¶…è¿‡ä¸€ä¸ªæœˆçš„æ—§ç¼“å­˜æ–‡ä»¶ï¼Œä¿ç•™æ–°ç¼“å­˜"""
    try:
        clear_old_cache()
    except Exception as e:
        print(f"æ¸…ç†ç¼“å­˜å¤±è´¥: {e}")


def extract_iocs_from_strings(text: str) -> Tuple[List[str], List[str], List[str]]:
    """ä»æ–‡æœ¬ä¸­æå– IOCï¼ˆIPã€åŸŸåã€URLï¼‰"""
    ips = []
    domains = []
    urls = []
    
    # æå– IP åœ°å€
    ip_pattern = r'\b(?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.){3}(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\b'
    ips = re.findall(ip_pattern, text)
    
    # æå– URL
    url_pattern = r'https?://[^\s<>"{}|\\^`\[\]]+'
    urls = re.findall(url_pattern, text)
    
    # ä» URL ä¸­æå–åŸŸå
    for url in urls:
        domain_match = re.search(r'https?://([^/]+)', url)
        if domain_match:
            domain = domain_match.group(1)
            if domain not in domains:
                domains.append(domain)
    
    # æå–å…¶ä»–åŸŸåï¼ˆé IPï¼‰
    domain_pattern = r'\b(?:[a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?\.)+[a-zA-Z]{2,}\b'
    found_domains = re.findall(domain_pattern, text)
    for domain in found_domains:
        # æ£€æŸ¥æ˜¯å¦æ˜¯ IP åœ°å€
        if not re.match(ip_pattern, domain) and domain not in domains and domain not in ips:
            domains.append(domain)
    
    return list(dict.fromkeys(ips)), list(dict.fromkeys(domains)), list(dict.fromkeys(urls))


def is_md5(value: str) -> bool:
    return bool(re.fullmatch(r"[a-fA-F0-9]{32}", value))


def is_sha1(value: str) -> bool:
    return bool(re.fullmatch(r"[a-fA-F0-9]{40}", value))


def is_sha256(value: str) -> bool:
    return bool(re.fullmatch(r"[a-fA-F0-9]{64}", value))


def extract_indicators(text: str) -> Tuple[List[str], List[str]]:
    ips = re.findall(r"\b(?:(?:2(5[0-5]|[0-4]\d))|(?:1?\d?\d))(?:\.(?:(?:2(5[0-5]|[0-4]\d))|(?:1?\d?\\d))){3}\b", text)
    ips = [m[0] if isinstance(m, tuple) else m for m in ips]
    # ç®€å•åŸŸååŒ¹é…ï¼ˆæ’é™¤çº¯æ•°å­—ä¸å·²åŒ¹é… IPï¼‰
    domains = re.findall(r"\b(?:[a-zA-Z0-9-]{1,63}\.)+[a-zA-Z]{2,}\b", text)
    domains = [d for d in domains if not re.fullmatch(r"\d+(?:\.\d+){3}", d)]
    return list(dict.fromkeys(ips)), list(dict.fromkeys(domains))


def vt_lookup(hash_value: str, api_key: str) -> Dict[str, Any]:
    # é¦–å…ˆæ£€æŸ¥å†…å­˜ç¼“å­˜
    cached_result = get_cached_data_memory(hash_value, "vt_result")
    if cached_result:
        print(f"ğŸ“¦ ä½¿ç”¨ VirusTotal ç¼“å­˜æ•°æ®")
        return cached_result
    
    # æ²¡æœ‰ç¼“å­˜ï¼Œè¿›è¡Œå®Œæ•´ API æŸ¥è¯¢
    headers = {"x-apikey": api_key}
    url = f"https://www.virustotal.com/api/v3/files/{hash_value}"
    r = requests.get(url, headers=headers, timeout=30)
    if r.status_code != 200:
        return {"source": "VirusTotal", "hit": False, "error": r.text}
    data = r.json()
    
    # ä¿å­˜åŸå§‹ JSON æ•°æ®
    save_json_data(hash_value, "virustotal", data)
    attrs = data.get("data", {}).get("attributes", {})
    stats = attrs.get("last_analysis_stats", {})
    names = attrs.get("names", [])
    cls = attrs.get("popular_threat_classification", {})
    label = (cls.get("suggested_threat_label") or "")
    
    # ç®€åŒ–å¨èƒæ ‡ç­¾æ˜¾ç¤º - åªæ˜¾ç¤ºä¸»è¦å¨èƒç±»å‹å’Œå‘½ä¸­æ¬¡æ•°
    threat_tags = []
    if label:
        threat_tags.append(label)
    
    # ä» popular_threat_category æå–ä¸»è¦å¨èƒç±»å‹å’Œå‘½ä¸­æ¬¡æ•°
    if cls:
        threat_categories = cls.get("popular_threat_category", [])
        if threat_categories:
            for cat in threat_categories:
                if isinstance(cat, dict) and cat.get("value") and cat.get("count"):
                    threat_tags.append(f"{cat['value']} ({cat['count']}æ¬¡)")
        
        threat_names = cls.get("popular_threat_name", [])
        if threat_names:
            for name in threat_names:
                if isinstance(name, dict) and name.get("value") and name.get("count"):
                    threat_tags.append(f"{name['value']} ({name['count']}æ¬¡)")
    # PE å…ƒä¿¡æ¯ï¼ˆå¦‚æœ‰ï¼‰â€” ä»…å¯¼å…¥/å¯¼å‡º
    pe_info = attrs.get("pe_info") or {}
    imports: List[str] = []
    exports: List[str] = []
    if pe_info:
        for lib in pe_info.get("import_list", []) or []:
            dll = lib.get("library_name")
            for fn in lib.get("imported_functions", []) or []:
                if dll and fn:
                    imports.append(f"{dll}!{fn}")
        for ex in pe_info.get("exported_functions", []) or []:
            if ex:
                exports.append(str(ex))

    # å…³è”å…³ç³»ï¼ˆç½‘ç»œ IOCã€URLã€æ–‡ä»¶è½åœ°ç­‰ï¼‰ä» relationships ä¸ behaviour_summary æå–
    def _vt_rel(rel: str) -> List[Dict[str, Any]]:
        rel_url = f"https://www.virustotal.com/api/v3/files/{hash_value}/relationships/{rel}"
        try:
            rr = requests.get(rel_url, headers=headers, timeout=30)
            if rr.status_code != 200:
                return []
            return rr.json().get("data", []) or []
        except Exception:
            return []

    contacted_ips = _vt_rel("contacted_ips")
    contacted_domains = _vt_rel("contacted_domains")
    contacted_urls = _vt_rel("contacted_urls")
    dropped_rel = _vt_rel("dropped_files")

    net_ips = []
    for it in contacted_ips:
        attr = (it.get("attributes") or {})
        ip = attr.get("ip_address") or it.get("id")
        if ip:
            net_ips.append(ip)
    net_domains = []
    for it in contacted_domains:
        dom = it.get("id")
        if dom:
            net_domains.append(dom)
    urls = []
    for it in contacted_urls:
        attr = (it.get("attributes") or {})
        u = attr.get("url") or it.get("id")
        if u:
            urls.append(u)
    dropped = []
    for it in dropped_rel:
        attr = (it.get("attributes") or {})
        sha256 = attr.get("sha256") or it.get("id")
        if sha256:
            dropped.append(sha256)

    # è¡Œä¸ºæ‘˜è¦ï¼ˆè¿›ç¨‹ä¸è¿›ç¨‹æ ‘ï¼‰
    procs: List[str] = []
    proc_nodes: List[Dict[str, Any]] = []
    behavior_data = {
        "shell_commands": [],
        "processes_created": [],
        "processes_terminated": [],
        "services_opened": [],
        "files_written": []
    }
    
    try:
        # ä¸º behaviour_summary å¢åŠ é‡è¯•ä¸å¯é€‰å…³é—­è¯ä¹¦æ ¡éªŒ
        from requests.adapters import HTTPAdapter
        from urllib3.util.retry import Retry
        import requests as _rq
        _session = _rq.Session()
        _session.mount("https://", HTTPAdapter(max_retries=Retry(total=3, backoff_factor=0.5, status_forcelist=(429, 500, 502, 503, 504))))
        _verify = os.environ.get("VT_VERIFY", "1") not in {"0", "false", "False"}
        bs = _session.get(f"https://www.virustotal.com/api/v3/files/{hash_value}/behaviour_summary", headers=headers, timeout=30, verify=_verify)
        if bs.status_code == 200:
            bsj = bs.json().get("data", {})
            
            
            # æå–è¿›ç¨‹ä¿¡æ¯
            for p in bsj.get("processes", []) or []:
                name = p.get("name") or p.get("image")
                if name:
                    procs.append(name)
                if isinstance(p, dict):
                    node = {"pid": p.get("pid"), "ppid": p.get("ppid"), "name": name}
                    if node["pid"] is not None or node["name"]:
                        proc_nodes.append(node)
            
            # æå–è¡Œä¸ºæ•°æ®
            # Shell commands - ä½¿ç”¨æ­£ç¡®çš„å­—æ®µå command_executions
            commands = bsj.get("command_executions", [])
            if isinstance(commands, list):
                for cmd in commands:
                    if isinstance(cmd, str) and cmd.strip():
                        behavior_data["shell_commands"].append(cmd.strip())
                    elif isinstance(cmd, dict):
                        # å°è¯•ä¸åŒçš„å‘½ä»¤å­—æ®µ
                        cmd_text = cmd.get("command") or cmd.get("cmd") or cmd.get("executable") or cmd.get("args")
                        if cmd_text and cmd_text.strip():
                            behavior_data["shell_commands"].append(cmd_text.strip())
            
            # Processes created
            for proc in bsj.get("processes_created", []) or []:
                if isinstance(proc, str) and proc.strip():
                    behavior_data["processes_created"].append(proc.strip())
            
            # Processes terminated
            for proc in bsj.get("processes_terminated", []) or []:
                if isinstance(proc, str) and proc.strip():
                    behavior_data["processes_terminated"].append(proc.strip())
            
            # Services opened
            for service in bsj.get("services_opened", []) or []:
                if isinstance(service, str) and service.strip():
                    behavior_data["services_opened"].append(service.strip())
            
            # Files written
            for file in bsj.get("files_written", []) or []:
                if isinstance(file, str) and file.strip():
                    behavior_data["files_written"].append(file.strip())
            
            # è¿½åŠ ä»è¡Œä¸ºè·å–çš„ç½‘ç»œ IOCï¼ˆå¦‚å¯ç”¨ï¼‰
            for ip in bsj.get("contacted_ips", []) or []:
                if isinstance(ip, str):
                    net_ips.append(ip)
            for dom in bsj.get("contacted_domains", []) or []:
                if isinstance(dom, str):
                    net_domains.append(dom)
            for u in bsj.get("contacted_urls", []) or []:
                if isinstance(u, str):
                    urls.append(u)
    except Exception as e:
        # ç½‘ç»œ/SSL é—®é¢˜ä¸åº”ä¸­æ–­æ•´ä½“æµç¨‹ï¼Œä»…æç¤ºä¸€æ¬¡
        print(f"âš ï¸ Behaviour Summary é”™è¯¯: {e}")

    # æ—¶é—´æ ¼å¼åŒ–
    def _fmt(ts):
        try:
            if isinstance(ts, (int, float)):
                return datetime.utcfromtimestamp(int(ts)).strftime("%Y-%m-%d")
        except Exception:
            return ts
        return ts

    result = {
        "source": "VirusTotal",
        "hit": True,
        "summary": {
            "æ£€æµ‹ç»Ÿè®¡": {
                "æ¶æ„": stats.get("malicious", 0),
                "å¯ç–‘": stats.get("suspicious", 0), 
                "æ— å®³": stats.get("harmless", 0),
                "æœªæ£€æµ‹": stats.get("undetected", 0),
                "å¤±è´¥": stats.get("failure", 0) + stats.get("timeout", 0) + stats.get("type-unsupported", 0)
            },
            "æ ·æœ¬åˆ«å": names[:10],
            "å¨èƒæ ‡ç­¾": threat_tags if threat_tags else [],
            "æ–‡ä»¶ç±»å‹": attrs.get("type_description"),
            "é¦–æ¬¡è§åˆ°": _fmt(attrs.get("first_submission_date")),
            "æœ€ååˆ†æ": _fmt(attrs.get("last_analysis_date")),
            # ä¸åšè£å‰ªï¼Œå®Œæ•´è¾“å‡ºå¯¼å…¥/å¯¼å‡ºå‡½æ•°ï¼ˆå±•ç¤ºå±‚è‡ªè¡Œåˆ†ç»„/å»é‡ï¼‰
            "å¯¼å…¥å‡½æ•°": imports,
            "å¯¼å‡ºå‡½æ•°": exports,
        },
        "raw": attrs,
        "ioc": {"ips": list(dict.fromkeys(net_ips)), "domains": list(dict.fromkeys(net_domains)), "urls": list(dict.fromkeys(urls[:100]))},
        "dropped": list(dict.fromkeys(dropped[:50])),
        "processes": list(dict.fromkeys(procs[:50])),
        "process_tree": proc_nodes[:200],
        "behavior": behavior_data,
    }
    
    # ä¿å­˜å®Œæ•´ç»“æœåˆ°ç¼“å­˜
    save_json_data(hash_value, "vt_result", result)
    return result


def bazaar_lookup(hash_value: str, api_key: str) -> Dict[str, Any]:
    # é¦–å…ˆæ£€æŸ¥å†…å­˜ç¼“å­˜
    cached_data = get_cached_data_memory(hash_value, "bazaar")
    if cached_data:
        print(f"ğŸ“¦ ä½¿ç”¨ MalwareBazaar ç¼“å­˜æ•°æ®")
        js = cached_data
    else:
        # æ²¡æœ‰ç¼“å­˜ï¼Œè¿›è¡Œ API æŸ¥è¯¢
        url = "https://mb-api.abuse.ch/api/v1/"
        s = requests.Session()
        s.headers.update({"accept": "application/json", "Auth-Key": api_key})
        
        # é¦–å…ˆå°è¯• get_info æŸ¥è¯¢
        resp = s.post(url, data={"query": "get_info", "hash": hash_value}, timeout=30)
        try:
            js = resp.json()
            # ä¿å­˜å®Œæ•´ JSON æ•°æ®
            save_json_data(hash_value, "bazaar", js)
        except Exception:
            return {"source": "MalwareBazaar", "hit": False, "error": resp.text}
    
    # å¦‚æœ get_info æ²¡æœ‰æ‰¾åˆ°ï¼Œå°è¯•å…¶ä»–æŸ¥è¯¢æ–¹æ³•
    if js.get("query_status") in {"hash_not_found", "no_results"}:
        # å°è¯•é€šè¿‡ imphash æŸ¥è¯¢ï¼ˆå¦‚æœæ˜¯ PE æ–‡ä»¶ï¼‰
        try:
            # ä» VirusTotal è·å– imphashï¼ˆå¦‚æœå¯ç”¨ï¼‰
            vt_data = check_cache_and_load(hash_value, "vt_result")
            if vt_data and vt_data.get("hit"):
                pe_info = vt_data.get("raw", {}).get("pe_info", {})
                imphash = pe_info.get("imphash")
                if imphash:
                    resp = s.post(url, data={"query": "get_imphash", "imphash": imphash}, timeout=30)
                    try:
                        js = resp.json()
                        if js.get("query_status") not in {"hash_not_found", "no_results"}:
                            save_json_data(hash_value, "bazaar", js)
                    except Exception:
                        pass
        except Exception:
            pass
        
        # å¦‚æœä»ç„¶æ²¡æœ‰æ‰¾åˆ°ï¼Œå°è¯•é€šè¿‡ç­¾åæŸ¥è¯¢
        if js.get("query_status") in {"hash_not_found", "no_results"}:
            try:
                # ä» VirusTotal è·å–ç­¾åä¿¡æ¯
                vt_data = check_cache_and_load(hash_value, "vt_result")
                if vt_data and vt_data.get("hit"):
                    signature = vt_data.get("summary", {}).get("å®¶æ—/ç­¾å", "")
                    if signature and signature != "å¨èƒåˆ†æ•°: 10":
                        # å°è¯•é€šè¿‡ç­¾åæŸ¥è¯¢
                        resp = s.post(url, data={"query": "get_taginfo", "tag": signature}, timeout=30)
                        try:
                            js = resp.json()
                            if js.get("query_status") not in {"hash_not_found", "no_results"}:
                                save_json_data(hash_value, "bazaar", js)
                        except Exception:
                            pass
            except Exception:
                pass
    
    if js.get("query_status") in {"hash_not_found", "no_results"}:
        return {"source": "MalwareBazaar", "hit": False}
    
    data = (js.get("data") or [])
    first = data[0] if data else {}
    vendor_intel = first.get("vendor_intel") or {}
    comment = first.get("comment") or ""
    
    # æå–æ›´å¤šä¿¡æ¯
    intelligence = first.get("intelligence", {})
    clamav = intelligence.get("clamav", [])
    downloads = intelligence.get("downloads", "0")
    uploads = intelligence.get("uploads", "0")
    
    return {
        "source": "MalwareBazaar",
        "hit": True,
        "summary": {
            "æ–‡ä»¶å": first.get("file_name"),
            "å®¶æ—/ç­¾å": first.get("signature"),
            "æ ‡ç­¾": first.get("tags"),
            "å›½å®¶": first.get("origin_country"),
            "æ–‡ä»¶å¤§å°": first.get("file_size"),
            "æ–‡ä»¶ç±»å‹": first.get("file_type"),
            "é¦–æ¬¡å‘ç°": first.get("first_seen"),
            "æœ€åå‘ç°": first.get("last_seen"),
            "ä¸‹è½½æ¬¡æ•°": downloads,
            "ä¸Šä¼ æ¬¡æ•°": uploads,
            "ClamAVæ£€æµ‹": clamav[:5] if clamav else [],
        },
        "raw": first,
        "notes": comment,
        "vendor_intel": vendor_intel,
        "intelligence": intelligence,
    }


def threatfox_lookup(ioc: str, api_key: str) -> Dict[str, Any]:
    # é¦–å…ˆæ£€æŸ¥å†…å­˜ç¼“å­˜
    cached_data = get_cached_data_memory(ioc, "threatfox")
    if cached_data:
        print(f"ğŸ“¦ ä½¿ç”¨ ThreatFox ç¼“å­˜æ•°æ®")
        js = cached_data
    else:
        # æ²¡æœ‰ç¼“å­˜ï¼Œè¿›è¡Œ API æŸ¥è¯¢
        url = "https://threatfox-api.abuse.ch/api/v1/"
        s = requests.Session()
        s.headers.update({"accept": "application/json", "Auth-Key": api_key, "Content-Type": "application/json"})
        # ä¼˜å…ˆå°è¯• ioc: å‰ç¼€ï¼ˆä¾‹å¦‚ ioc:payload.tahirvoip.shopï¼‰ï¼Œä¸å‘½ä¸­å†å›é€€åŸå€¼
        js = {}
        for term in (f"ioc:{ioc}", ioc):
            try:
                resp = s.post(url, data=json.dumps({"query": "search_ioc", "search_term": term}), timeout=30)
                tmp = resp.json()
                if tmp.get("query_status") != "no_result":
                    js = tmp
                    break
            except Exception:
                continue
        
        # ä¿å­˜å®Œæ•´ JSON æ•°æ®
        # ThreatFox ç»“æœå†™å…¥ url_tmpï¼ˆè€Œé tmpï¼‰
        save_url_json(ioc, "threatfox", js)
    if not js or js.get("query_status") == "no_result":
        return {"source": "ThreatFox", "hit": False}
    items = js.get("data") or []
    # è§£æ ThreatFox è¿”å›çš„ IOC ç±»å‹
    tf_ips: List[str] = []
    tf_domains: List[str] = []
    tf_urls: List[str] = []
    # æ±‡æ€»ThreatFoxå…³é”®ä¿¡æ¯ï¼ˆç±»å‹/åˆ«å/ç½®ä¿¡åº¦/æ—¶é—´/å›½å®¶ï¼‰
    threat_types: List[str] = []
    malware_aliases: List[str] = []
    confidences: List[str] = []
    first_seen_list: List[str] = []
    last_seen_list: List[str] = []
    countries: List[str] = []
    tf_tags: List[str] = []
    refs: List[str] = []
    for it in items:
        val = it.get("ioc") or ""
        t = (it.get("ioc_type") or "").lower()
        if not val:
            continue
        if t in {"ip", "ipv4", "ipv6"}:
            tf_ips.append(val)
        elif t in {"domain", "fqdn"}:
            tf_domains.append(val)
        elif t in {"url"}:
            tf_urls.append(val)
        # æ±‡æ€»é™„åŠ å­—æ®µ
        th_type = it.get("threat_type") or it.get("threat_type_desc") or it.get("threat_type_label")
        if th_type:
            threat_types.append(str(th_type))
        # å®Œæ•´æ¶æ„å®¶æ—åˆ«åï¼šå…¼å®¹å¤šå­—æ®µ/åˆ—è¡¨/é€—å·åˆ†éš”
        malias_val = (
            it.get("malware_alias")
            or it.get("malware_aliases")
            or it.get("malware_printable")
            or it.get("malware_family")
            or it.get("malware")
        )
        if malias_val:
            if isinstance(malias_val, list):
                malware_aliases.append(", ".join([str(x) for x in malias_val if x]))
            else:
                malware_aliases.append(str(malias_val))
        conf = it.get("confidence_level")
        if conf is not None:
            confidences.append(str(conf))
        fs = it.get("first_seen") or it.get("first_seen_utc")
        if fs:
            first_seen_list.append(str(fs))
        ls = it.get("last_seen") or it.get("last_seen_utc")
        if ls:
            last_seen_list.append(str(ls))
        ctry = it.get("country") or it.get("cc")
        if ctry:
            countries.append(str(ctry))
        tags_val = it.get("tags") or it.get("tag")
        if tags_val:
            if isinstance(tags_val, list):
                tf_tags.extend([str(x) for x in tags_val if x])
            else:
                # é€—å·åˆ†éš”æˆ–å­—ç¬¦ä¸²
                tf_tags.extend([s.strip() for s in str(tags_val).split(',') if s.strip()])
        ref = it.get("reference") or it.get("reference_link") or it.get("urlhaus_reference")
        if ref:
            refs.append(str(ref))
    # å»é‡
    threat_types = list(dict.fromkeys(threat_types))
    malware_aliases = list(dict.fromkeys(malware_aliases))
    confidences = list(dict.fromkeys(confidences))
    first_seen_list = list(dict.fromkeys(first_seen_list))
    last_seen_list = list(dict.fromkeys(last_seen_list))
    countries = list(dict.fromkeys(countries))
    summary = {}
    if threat_types:
        summary["Threat Type"] = threat_types
    if malware_aliases:
        summary["Malware alias"] = malware_aliases
    if confidences:
        summary["Confidence Level"] = confidences
    if first_seen_list:
        summary["First seen"] = first_seen_list[0]
    if last_seen_list:
        summary["Last seen"] = last_seen_list[0]
    if countries:
        summary["Country"] = countries
    if refs:
        summary["Reference"] = list(dict.fromkeys(refs))
        # è‡ªåŠ¨æŠ½å– Triage æ ·æœ¬IDåˆ—è¡¨ï¼Œä¾›ä¸Šå±‚è§¦å‘è¡¥æŸ¥
        triage_ids: List[str] = []
        for rlink in summary["Reference"]:
            m = re.search(r"(\d{6,}-[A-Za-z0-9]+)", rlink)
            if m:
                triage_ids.append(m.group(1))
        if triage_ids:
            summary["TriageIDs"] = list(dict.fromkeys(triage_ids))
    if tf_tags:
        summary["Tags"] = list(dict.fromkeys(tf_tags))
    return {
        "source": "ThreatFox",
        "hit": bool(items),
        "items": items,
        "summary": summary,
        "ioc": {"ips": list(dict.fromkeys(tf_ips)), "domains": list(dict.fromkeys(tf_domains)), "urls": list(dict.fromkeys(tf_urls))},
    }


def threatfox_multi_lookup(indicator: str, api_key: str) -> Dict[str, Any]:
    """Try multiple ThreatFox strategies: search_ioc with and without ioc: prefix; fallback to get_iocs(days=7) and filter."""
    best = threatfox_lookup(indicator, api_key)
    if best.get("hit"):
        return best
    # fallback: get_iocs last 7 days and filter (per API, max 7)
    url = "https://threatfox-api.abuse.ch/api/v1/"
    s = requests.Session()
    s.headers.update({"accept": "application/json", "Auth-Key": api_key, "Content-Type": "application/json"})
    try:
        resp = s.post(url, data=json.dumps({"query": "get_iocs", "days": 7}), timeout=30)
        js = resp.json()
        data = js.get("data") or []
        if not data:
            return {"source": "ThreatFox", "hit": False}
        ips: List[str] = []
        domains: List[str] = []
        urls: List[str] = []
        key = indicator.lower()
        for it in data:
            ioc_val = (it.get("ioc") or "").lower()
            if not ioc_val:
                continue
            if key in ioc_val:
                t = (it.get("ioc_type") or "").lower()
                if t in {"ip", "ipv4", "ipv6"}:
                    ips.append(it.get("ioc"))
                elif t in {"domain", "fqdn"}:
                    domains.append(it.get("ioc"))
                elif t in {"url"}:
                    urls.append(it.get("ioc"))
        hit = bool(ips or domains or urls)
        return {"source": "ThreatFox", "hit": hit, "ioc": {"ips": list(dict.fromkeys(ips)), "domains": list(dict.fromkeys(domains)), "urls": list(dict.fromkeys(urls))}}
    except Exception:
        return {"source": "ThreatFox", "hit": False}


def alienvault_lookup(hash_value: str, api_key: str) -> Dict[str, Any]:
    # é¦–å…ˆæ£€æŸ¥å†…å­˜ç¼“å­˜
    cached_data = get_cached_data_memory(hash_value, "alienvault")
    if cached_data:
        print(f"ğŸ“¦ ä½¿ç”¨ AlienVault ç¼“å­˜æ•°æ®")
        js = cached_data
    else:
        # æ²¡æœ‰ç¼“å­˜ï¼Œè¿›è¡Œ API æŸ¥è¯¢
        url = f"https://otx.alienvault.com/api/v1/indicators/file/{hash_value}/general"
        headers = {"X-OTX-API-KEY": api_key}
        r = requests.get(url, headers=headers, timeout=30)
        if r.status_code != 200:
            return {"source": "AlienVault", "hit": False, "error": r.text}
        js = r.json()
        
        # ä¿å­˜å®Œæ•´ JSON æ•°æ®
        save_json_data(hash_value, "alienvault", js)
    
    pulse_info = (js.get("pulse_info") or {})
    pulses = pulse_info.get("pulses") or []
    # ä» OTX è„‰å†²æå– IOC
    av_ips: List[str] = []
    av_domains: List[str] = []
    av_urls: List[str] = []
    for p in pulses:
        for ind in p.get("indicators", []) or []:
            val = ind.get("indicator") or ""
            t = (ind.get("type") or "").lower()
            if not val:
                continue
            if t in {"ipv4", "ipv6", "ip"}:
                av_ips.append(val)
            elif t in {"domain", "hostname"}:
                av_domains.append(val)
            elif t in {"url", "uri"}:
                av_urls.append(val)
    # æ„å»ºå¯ç”¨äºç»Ÿä¸€æ‘˜è¦çš„æœ€å°è¡¥ä½ä¿¡æ¯ï¼ˆä¸æ”¹å˜ VT æ¨¡ç‰ˆï¼Œä»…åœ¨ç¼ºå¤±æ—¶å¯è¢«åˆå¹¶é€»è¾‘æ‹¾å–ï¼‰
    def _unique(seq: List[str]) -> List[str]:
        return list(dict.fromkeys([s for s in seq if s]))
    tag_list: List[str] = []
    ref_list: List[str] = []
    first_seen: List[str] = []
    last_seen: List[str] = []
    for p in pulses:
        # tags
        if isinstance(p.get("tags"), list):
            tag_list.extend([str(x) for x in p.get("tags") if x])
        # references
        refs = p.get("references")
        if isinstance(refs, list):
            ref_list.extend([str(x) for x in refs if x])
        elif isinstance(refs, str):
            ref_list.append(refs)
        # times
        if p.get("created"):
            first_seen.append(str(p.get("created")))
        if p.get("modified"):
            last_seen.append(str(p.get("modified")))
    summary: Dict[str, Any] = {}
    if tag_list:
        summary["æ ‡ç­¾"] = _unique(tag_list)
    if first_seen:
        summary["é¦–æ¬¡å‘ç°"] = first_seen[0]
    if last_seen:
        summary["æœ€åå‘ç°"] = last_seen[0]
    if ref_list:
        summary["å‚è€ƒ"] = _unique(ref_list)
    hit = bool(pulses)

    # è‹¥ general æ— è„‰å†²ï¼Œå°è¯• analysis ç«¯ç‚¹è¡¥å……ï¼ˆä¸æ”¹å˜ VT æ¨¡ç‰ˆï¼Œä»…è¡¥ä½å¯ç”¨å­—æ®µï¼‰
    analysis_raw: Dict[str, Any] = {}
    if not hit:
        try:
            r2 = requests.get(f"https://otx.alienvault.com/api/v1/indicators/file/{hash_value}/analysis", headers=headers, timeout=30)
            if r2.status_code == 200:
                analysis_raw = r2.json()
                # é‡‡å–ä¿å®ˆæå–ï¼šä»åŸå§‹æ–‡æœ¬ä¸­æ­£åˆ™æŠ“å– IOCï¼Œä»¥é¿å…ç»“æ„å·®å¼‚å¯¼è‡´æ¼æŠ“
                try:
                    text_blob = json.dumps(analysis_raw, ensure_ascii=False)
                    # URLs
                    for u in re.findall(r"https?://[A-Za-z0-9_\-\.:%/#?=&]+", text_blob):
                        av_urls.append(u)
                    # IPv4
                    for ip in re.findall(r"\b(?:(?:25[0-5]|2[0-4]\d|[01]?\d?\d)\.){3}(?:25[0-5]|2[0-4]\d|[01]?\d?\d)\b", text_blob):
                        av_ips.append(ip)
                    # Domainsï¼ˆç²—ç•¥æå–ï¼Œé¿å…ä¸ IP å†²çªï¼‰
                    for dom in re.findall(r"\b(?:(?:[a-zA-Z0-9-]{1,63})\.)+[a-zA-Z]{2,}\b", text_blob):
                        if not re.match(r"^\d+(?:\.\d+){3}$", dom):
                            av_domains.append(dom)
                    if (not summary.get("æ ‡ç­¾")) and "plugins" in analysis_raw:
                        # ä¾‹å¦‚ yara/malware_classification çš„æ ‡ç­¾å
                        tags_tmp: List[str] = []
                        try:
                            for k, v in (analysis_raw.get("plugins") or {}).items():
                                if isinstance(v, dict):
                                    n = v.get("name") or k
                                    if n:
                                        tags_tmp.append(str(n))
                        except Exception:
                            pass
                        if tags_tmp:
                            summary["æ ‡ç­¾"] = list(dict.fromkeys(tags_tmp))
                except Exception:
                    pass
                # è‹¥æŠ“å–åˆ°ä»»ä½• IOCï¼Œåˆ™è§†ä¸ºå‘½ä¸­
                if av_urls or av_domains or av_ips:
                    hit = True
        except Exception:
            pass

    return {
        "source": "AlienVault",
        "hit": hit,
        "summary": summary,
        "pulses": pulses[:5],
        "ioc": {"ips": list(dict.fromkeys(av_ips)), "domains": list(dict.fromkeys(av_domains)), "urls": list(dict.fromkeys(av_urls))},
        "raw": {"general": js, "analysis": analysis_raw} if analysis_raw else js,
    }


def inquest_lookup(hash_value: str, api_key: str) -> Dict[str, Any]:
    # é¦–å…ˆæ£€æŸ¥å†…å­˜ç¼“å­˜
    cached_data = get_cached_data_memory(hash_value, "inquest")
    if cached_data:
        print(f"ğŸ“¦ ä½¿ç”¨ InQuest ç¼“å­˜æ•°æ®")
        js = cached_data
    else:
        # æ²¡æœ‰ç¼“å­˜ï¼Œè¿›è¡Œ API æŸ¥è¯¢
        base = "https://labs.inquest.net/api/iad/"
        endpoint = "sample/info/sha256/" if is_sha256(hash_value) else ("sample/info/md5/" if is_md5(hash_value) else None)
        if not endpoint:
            return {"source": "InQuest", "hit": False}
        url = base + endpoint + hash_value
        headers = {"Authorization": f"Bearer {api_key}"}
        r = requests.get(url, headers=headers, timeout=30)
        if r.status_code != 200:
            return {"source": "InQuest", "hit": False, "error": r.text}
        js = r.json()
        
        # ä¿å­˜å®Œæ•´ JSON æ•°æ®
        save_json_data(hash_value, "inquest", js)
    
    return {
        "source": "InQuest",
        "hit": True,
        "raw": js,
    }


def inquest_ioc_lookup(target: str) -> Dict[str, Any]:
    """InQuest Labs IOC æŸ¥è¯¢ï¼ˆåŸŸå/IPï¼‰ï¼Œç”¨äºè¡¥å……ç½‘ç»œæƒ…æŠ¥ã€‚
    æ–‡æ¡£: https://labs.inquest.net/docs/ ï¼ˆå…¬å…± Labs é€šå¸¸æ— éœ€ API Keyï¼‰
    """
    base = "https://labs.inquest.net/api/ioc"
    try:
        r = requests.get(base, params={"q": target}, timeout=30)
        if r.status_code != 200:
            return {"source": "InQuest", "hit": False, "error": r.text}
        js = r.json()
    except Exception as e:
        return {"source": "InQuest", "hit": False, "error": str(e)}

    # å…¼å®¹è¿”å›ï¼šæœ‰çš„æ¥å£è¿”å›å¯¹è±¡ï¼Œæœ‰çš„è¿”å›åˆ—è¡¨
    items = []
    if isinstance(js, list):
        items = js
    elif isinstance(js, dict):
        # å¸¸è§å­—æ®µï¼šdata/list/results
        for key in ("data", "list", "results", "ioc"):
            if isinstance(js.get(key), list):
                items = js.get(key)
                break
        if not items:
            items = [js]

    # è§£æå…³é”®ä¿¡æ¯
    urls: List[str] = []
    ips: List[str] = []
    domains: List[str] = []
    threat_types: List[str] = []
    countries: List[str] = []
    first_seen: List[str] = []
    last_seen: List[str] = []

    for it in items:
        if not isinstance(it, dict):
            continue
        val = str(it.get("ioc") or it.get("value") or it.get("data") or "").strip()
        ioc_type = (it.get("type") or it.get("category") or "").lower()
        if val:
            if ioc_type in {"ip", "ipv4", "ipv6"} or (":" not in val and val.replace(".", "").isdigit()):
                ips.append(val)
            elif ioc_type in {"domain", "hostname", "fqdn"} or ("/" not in val and "." in val):
                domains.append(val)
            elif ioc_type in {"url", "uri"} or val.startswith(("http://", "https://")):
                urls.append(val)
        tt = it.get("threat_type") or it.get("classification") or it.get("label")
        if tt:
            threat_types.append(str(tt))
        c = it.get("country") or it.get("cc")
        if c:
            countries.append(str(c))
        fs = it.get("first_seen") or it.get("created") or it.get("date_first_seen")
        if fs:
            first_seen.append(str(fs))
        ls = it.get("last_seen") or it.get("updated") or it.get("date_last_seen")
        if ls:
            last_seen.append(str(ls))

    # å»é‡
    urls = list(dict.fromkeys(urls))
    ips = list(dict.fromkeys(ips))
    domains = list(dict.fromkeys(domains))
    threat_types = list(dict.fromkeys(threat_types))
    countries = list(dict.fromkeys(countries))

    hit = bool(urls or ips or domains or threat_types or countries or first_seen or last_seen)
    summary: Dict[str, Any] = {}
    if threat_types:
        summary["Threat Type"] = threat_types
    if countries:
        summary["Country"] = countries
    if first_seen:
        summary["First seen"] = first_seen[0]
    if last_seen:
        summary["Last seen"] = last_seen[0]

    return {
        "source": "InQuest",
        "hit": hit,
        "summary": summary,
        "ioc": {"ips": ips, "domains": domains, "urls": urls},
        "raw": items,
    }


def hybrid_lookup(hash_value: str, api_key: str) -> Dict[str, Any]:
    base = "https://www.hybrid-analysis.com/api/v2"
    headers = {
        "user-agent": "Falcon Sandbox",
        "api-key": api_key,
        "X-Api-Key": api_key,
        "accept": "application/json",
    }
    
    # é¦–å…ˆæœç´¢å“ˆå¸Œæ˜¯å¦å­˜åœ¨ï¼›è‹¥æ— ç»“æœï¼Œåç»­èµ°ç›´æ¥ report/overview å›é€€
    env_id = None
    verdict = ""
    reported_envs: List[int] = []
    try:
        search_url = f"{base}/search/hash?hash={hash_value}"
        search_r = requests.get(search_url, headers=headers, timeout=30)
        if search_r.status_code == 200:
            search_data = search_r.json()
            reports = search_data.get("reports", [])
            if reports:
                # æ”¶é›†æ‰€æœ‰è¿”å›çš„ environment_idï¼Œå¹¶ä¼˜å…ˆ 100
                for report in reports:
                    env = report.get("environment_id")
                    if isinstance(env, int):
                        reported_envs.append(env)
                    if env == 100 and not env_id:
                        env_id = 100
                        verdict = report.get("verdict", "")
                if not env_id:
                    first_report = reports[0]
                    env_id = first_report.get("environment_id", 100)
                    verdict = first_report.get("verdict", "")
    except Exception:
        # å¿½ç•¥æœç´¢å¼‚å¸¸ï¼Œç»§ç»­å›é€€
        pass
    
    # ä½¿ç”¨æ‰¾åˆ°çš„ç¯å¢ƒIDè·å–è¯¦ç»†æŠ¥å‘Šï¼›è‹¥æ—  env_idï¼Œç›´æ¥å°è¯•å¤šç¯å¢ƒä¸ overview å›é€€
    r = None
    try_envs = [env_id] if env_id else []
    # å…ˆåŠ å…¥ search è¿”å›çš„æ‰€æœ‰ç¯å¢ƒï¼ˆä¿æŒå”¯ä¸€å¹¶ä¿åºï¼‰
    for env in reported_envs:
        if env and env not in try_envs:
            try_envs.append(env)
    # å†åŠ å…¥å¸¸è§ç¯å¢ƒä¼˜å…ˆçº§ï¼ˆåŒ…å« 160ï¼‰
    for default_env in [100, 110, 120, 160, 200, 300]:
        if default_env not in try_envs:
            try_envs.append(default_env)

    # å…ˆè¯• report/{hash}:{env}/summary
    for env in try_envs:
        try:
            rr = requests.get(f"{base}/report/{hash_value}:{env}/summary", headers=headers, timeout=30)
            if rr.status_code == 200:
                r = rr
                env_id = env
                break
        except Exception:
            continue

    # è‹¥ä»æœªè·å–ï¼Œå°è¯• overview/{hash}/summaryï¼ˆæœ‰äº›æ ·æœ¬ä»…è¯¥ç«¯ç‚¹å¯ç”¨ï¼‰
    if r is None:
        try:
            orr = requests.get(f"{base}/overview/{hash_value}/summary", headers=headers, timeout=30)
            if orr.status_code == 200:
                r = orr
        except Exception:
            pass

    # è‹¥ä»æœªè·å–ï¼Œä½¿ç”¨ terms æœç´¢å›é€€è¡¥å……ç¯å¢ƒå¹¶é‡è¯•
    if r is None:
        try:
            terms_r = requests.get(f"{base}/search/terms?query={hash_value}", headers=headers, timeout=30)
            if terms_r.status_code == 200:
                terms_data = terms_r.json() if callable(getattr(terms_r, 'json', None)) else {}
                # å…¼å®¹è¿”å›ç»“æ„ï¼šæœ‰çš„è¿”å› reportsï¼Œæœ‰çš„ç›´æ¥è¿”å›åˆ—è¡¨
                t_reports = []
                if isinstance(terms_data, dict):
                    t_reports = terms_data.get('reports') or terms_data.get('data') or []
                elif isinstance(terms_data, list):
                    t_reports = terms_data
                extra_envs: List[int] = []
                for rep in t_reports:
                    if isinstance(rep, dict):
                        env = rep.get('environment_id')
                        if isinstance(env, int):
                            extra_envs.append(env)
                # åˆå¹¶è¡¥å……ç¯å¢ƒå¹¶é‡è¯• summary
                for env in extra_envs:
                    if env not in try_envs:
                        try_envs.append(env)
                for env in try_envs:
                    try:
                        rr2 = requests.get(f"{base}/report/{hash_value}:{env}/summary", headers=headers, timeout=30)
                        if rr2.status_code == 200:
                            r = rr2
                            env_id = env
                            break
                    except Exception:
                        continue
        except Exception:
            pass

    if r is None or r.status_code != 200:
        last_text = getattr(r, 'text', '') if r is not None else 'all attempts failed'
        return {"source": "HybridAnalysis", "hit": False, "error": last_text}
    try:
        js = r.json()
        # ä¿å­˜å®Œæ•´ JSON æ•°æ®
        save_json_data(hash_value, "hybrid", js)
    except Exception:
        return {"source": "HybridAnalysis", "hit": False, "error": r.text}
    # æå– IOCï¼ˆsummaryï¼‰
    domains = js.get("domains") or []
    hosts = js.get("hosts") or []
    compromised = js.get("compromised_hosts") or []
    # è¿›ç¨‹ä¸ DNS/URL ç­‰ï¼ˆsummary èƒ½æä¾›çš„æœ‰é™ï¼‰
    procs = js.get("processes") or []
    urls = js.get("urls") or []
    dns = js.get("dns_requests") or []
    
    # ä» Memory Forensics å’Œ Interesting Strings ä¸­æå– IOC
    memory_iocs = js.get("mitre_attcks", []) or []
    for mitre in memory_iocs:
        if isinstance(mitre, dict):
            description = mitre.get("description", "")
            if description:
                # ä»æè¿°ä¸­æå– IOC
                mem_ips, mem_domains, mem_urls = extract_iocs_from_strings(description)
                hosts.extend(mem_ips)
                domains.extend(mem_domains)
                urls.extend(mem_urls)
    
    # ä» signatures æ•°ç»„ä¸­æå– IOC
    signatures = js.get("signatures", []) or []
    for sig in signatures:
        if isinstance(sig, dict):
            description = sig.get("description", "")
            if description:
                # ä»æè¿°ä¸­æå– IOC
                mem_ips, mem_domains, mem_urls = extract_iocs_from_strings(description)
                hosts.extend(mem_ips)
                domains.extend(mem_domains)
                urls.extend(mem_urls)

    # è¯¦ç»†ç«¯ç‚¹å°è¯•ï¼ˆç½‘ç»œã€DNSã€è¿›ç¨‹æ ‘ç­‰ï¼‰ï¼Œå¤±è´¥åˆ™å¿½ç•¥
    detailed: Dict[str, Any] = {}
    # è¯¦ç»†ç«¯ç‚¹ä¼˜å…ˆä½¿ç”¨å·²ç»ç¡®è®¤çš„ env_idï¼Œå¦åˆ™å°è¯• 100
    _env_for_detail = env_id or 100
    for endpoint in ("network", "dns", "processes"):
        try:
            rr = requests.get(f"{base}/report/{hash_value}:{_env_for_detail}/{endpoint}", headers=headers, timeout=30)
            if rr.status_code == 200:
                detailed[endpoint] = rr.json()
        except Exception:
            pass
    # åˆå¹¶è¯¦ç»†ç«¯ç‚¹çš„å¯è¯†åˆ«é¡¹
    try:
        net = detailed.get("network") or {}
        urls += net.get("urls", []) or []
        hosts += net.get("hosts", []) or []
        domains += net.get("domains", []) or []
    except Exception:
        pass
    try:
        dns_raw = detailed.get("dns") or []
        for d in dns_raw:
            if isinstance(d, dict) and d.get("query"):
                dns.append(d.get("query"))
    except Exception:
        pass
    try:
        procs_raw = detailed.get("processes") or []
        for p in procs_raw:
            if isinstance(p, dict) and p.get("name"):
                procs.append(p.get("name"))
    except Exception:
        pass
    # æå–æ ¸å¿ƒå¨èƒæƒ…æŠ¥æ•°æ®
    summary_data = {}
    threat_tags = []
    
    try:
        # åŸºæœ¬ä¿¡æ¯
        summary_data["æ–‡ä»¶å"] = js.get("submit_name", "")
        summary_data["æ–‡ä»¶å¤§å°"] = f"{js.get('size', 0)} bytes"
        summary_data["æ–‡ä»¶ç±»å‹"] = js.get("type", "")
        summary_data["ç¯å¢ƒ"] = js.get("environment_description", "")
        summary_data["çŠ¶æ€"] = js.get("state", "")
        summary_data["å¨èƒç­‰çº§"] = js.get("threat_level", "")
        summary_data["å¨èƒåˆ†æ•°"] = js.get("threat_score", "")
        summary_data["AVæ£€æµ‹"] = js.get("av_detect", 0)
        summary_data["æ¶æ„è½¯ä»¶å®¶æ—"] = js.get("vx_family", "")
        summary_data["åˆ†ææ—¶é—´"] = js.get("analysis_start_time", "")
        
        # å“ˆå¸Œå€¼ä¿¡æ¯
        summary_data["MD5"] = js.get("md5", "")
        summary_data["SHA1"] = js.get("sha1", "")
        summary_data["SHA256"] = js.get("sha256", "")
        summary_data["SHA512"] = js.get("sha512", "")
        summary_data["SSDeep"] = js.get("ssdeep", "")
        summary_data["ImpHash"] = js.get("imphash", "")
        
        # PE ä¿¡æ¯
        summary_data["å…¥å£ç‚¹"] = js.get("entrypoint", "")
        summary_data["å…¥å£ç‚¹æ®µ"] = js.get("entrypoint_section", "")
        summary_data["é•œåƒåŸºå€"] = js.get("image_base", "")
        summary_data["å­ç³»ç»Ÿ"] = js.get("subsystem", "")
        summary_data["ä¸»ç‰ˆæœ¬"] = js.get("major_os_version", "")
        summary_data["æ¬¡ç‰ˆæœ¬"] = js.get("minor_os_version", "")
        
        # å¨èƒæ ‡ç­¾æå–
        if verdict:
            threat_tags.append(f"verdict: {verdict}")
        
        # ä» classification_tags æå–
        classification_tags = js.get("classification_tags", [])
        if classification_tags:
            threat_tags.extend([str(tag) for tag in classification_tags if tag])
        
        # ä» tags æå–
        tags = js.get("tags", [])
        if tags:
            threat_tags.extend([str(tag) for tag in tags if tag])
        
        # ä» crowdstrike_ai æå–
        crowdstrike_ai = js.get("crowdstrike_ai", {})
        if crowdstrike_ai:
            for key, value in crowdstrike_ai.items():
                if value and isinstance(value, list) and value:
                    verdicts = []
                    for item in value:
                        if isinstance(item, dict) and item.get("verdict"):
                            verdicts.append(item["verdict"])
                    if verdicts:
                        unique_verdicts = list(dict.fromkeys(verdicts))
                        threat_tags.append(f"{key}: {', '.join(unique_verdicts)}")
                elif value and not isinstance(value, list):
                    threat_tags.append(f"{key}: {value}")
        
        # ä» machine_learning_models æå–
        ml_models = js.get("machine_learning_models", {})
        if ml_models:
            for model, result in ml_models.items():
                if result:
                    threat_tags.append(f"ML-{model}: {result}")
        
        # ä» signatures æå–å¨èƒæ ‡ç­¾
        signatures = js.get("signatures", [])
        if signatures:
            for sig in signatures:
                if isinstance(sig, dict):
                    sig_name = sig.get("name", "")
                    sig_desc = sig.get("description", "")
                    if sig_name:
                        threat_tags.append(f"signature: {sig_name}")
                    if sig_desc and sig_desc != sig_name:
                        threat_tags.append(f"desc: {sig_desc}")
        
        # ä» mitre_attcks æå–
        mitre_attacks = js.get("mitre_attcks", [])
        if mitre_attacks:
            for attack in mitre_attacks:
                if isinstance(attack, dict):
                    attack_name = attack.get("name", "")
                    attack_desc = attack.get("description", "")
                    if attack_name:
                        threat_tags.append(f"MITRE: {attack_name}")
                    if attack_desc and attack_desc != attack_name:
                        threat_tags.append(f"technique: {attack_desc}")
        
        # ç»Ÿè®¡ä¿¡æ¯
        summary_data["ç½‘ç»œè¿æ¥æ•°"] = js.get("total_network_connections", 0)
        summary_data["è¿›ç¨‹æ•°"] = js.get("total_processes", 0)
        summary_data["ç­¾åæ•°"] = js.get("total_signatures", 0)
        summary_data["æå–æ–‡ä»¶æ•°"] = len(js.get("extracted_files", []))
        
    except Exception as e:
        print(f"âš ï¸ Hybrid Analysis æ•°æ®æå–é”™è¯¯: {e}")

    # å»é‡æ•´ç†
    hosts = list(dict.fromkeys(hosts)) if isinstance(hosts, list) else []
    compromised = list(dict.fromkeys(compromised)) if isinstance(compromised, list) else []
    domains = list(dict.fromkeys(domains)) if isinstance(domains, list) else []
    urls = list(dict.fromkeys(urls)) if isinstance(urls, list) else []
    dns = list(dict.fromkeys(dns)) if isinstance(dns, list) else []
    # ç¡®ä¿ procs åªåŒ…å«å­—ç¬¦ä¸²ï¼Œç„¶åå»é‡
    procs = [str(p) for p in procs if p] if isinstance(procs, list) else []
    procs = list(dict.fromkeys(procs))
    # æå–è¡Œä¸ºæ•°æ®
    behavior_data = {
        "processes_created": [],
        "processes_terminated": [],
        "files_created": [],
        "files_modified": [],
        "files_deleted": [],
        "registry_keys": [],
        "network_connections": [],
        "dns_requests": [],
        "signatures": [],
        "mitre_attacks": []
    }
    
    try:
        # ä» processes æå–è¿›ç¨‹ä¿¡æ¯
        processes = js.get("processes", [])
        if processes:
            for proc in processes:
                if isinstance(proc, dict):
                    proc_name = proc.get("name", "")
                    if proc_name:
                        behavior_data["processes_created"].append(proc_name)
        
        # ä» extracted_files æå–æ–‡ä»¶ä¿¡æ¯
        extracted_files = js.get("extracted_files", [])
        if extracted_files:
            for file_info in extracted_files:
                if isinstance(file_info, dict):
                    file_name = file_info.get("name", "")
                    if file_name:
                        behavior_data["files_created"].append(file_name)
        
        # ä» signatures æå–ç­¾åä¿¡æ¯
        signatures = js.get("signatures", [])
        if signatures:
            for sig in signatures:
                if isinstance(sig, dict):
                    sig_name = sig.get("name", "")
                    if sig_name:
                        behavior_data["signatures"].append(sig_name)
        
        # ä» mitre_attcks æå–æ”»å‡»æŠ€æœ¯
        mitre_attacks = js.get("mitre_attcks", [])
        if mitre_attacks:
            for attack in mitre_attacks:
                if isinstance(attack, dict):
                    attack_name = attack.get("name", "")
                    if attack_name:
                        behavior_data["mitre_attacks"].append(attack_name)
        
        # ä»è¯¦ç»†ç«¯ç‚¹æå–æ›´å¤šè¡Œä¸ºæ•°æ®
        if detailed.get("network"):
            network_data = detailed["network"]
            if isinstance(network_data, dict):
                # æå–ç½‘ç»œè¿æ¥
                network_connections = network_data.get("connections", [])
                if network_connections:
                    for conn in network_connections:
                        if isinstance(conn, dict):
                            conn_info = f"{conn.get('protocol', '')} {conn.get('host', '')}:{conn.get('port', '')}"
                            if conn_info.strip():
                                behavior_data["network_connections"].append(conn_info)
        
        if detailed.get("dns"):
            dns_data = detailed["dns"]
            if isinstance(dns_data, list):
                for dns_entry in dns_data:
                    if isinstance(dns_entry, dict):
                        dns_query = dns_entry.get("query", "")
                        if dns_query:
                            behavior_data["dns_requests"].append(dns_query)
        
        if detailed.get("processes"):
            processes_data = detailed["processes"]
            if isinstance(processes_data, list):
                for proc in processes_data:
                    if isinstance(proc, dict):
                        proc_name = proc.get("name", "")
                        if proc_name:
                            behavior_data["processes_created"].append(proc_name)
    
    except Exception as e:
        print(f"âš ï¸ Hybrid Analysis è¡Œä¸ºæ•°æ®æå–é”™è¯¯: {e}")
    
    # å»é‡è¡Œä¸ºæ•°æ®
    for key in behavior_data:
        behavior_data[key] = list(dict.fromkeys(behavior_data[key]))
    
    # å³ä½¿æœ‰é”™è¯¯çŠ¶æ€ï¼Œå¦‚æœæœ‰åŸºæœ¬ä¿¡æ¯ä¹Ÿåº”è¯¥æ˜¾ç¤º
    has_basic_info = bool(summary_data.get("æ–‡ä»¶å") or summary_data.get("æ¶æ„è½¯ä»¶å®¶æ—") or summary_data.get("AVæ£€æµ‹") or threat_tags)
    
    return {
        "source": "HybridAnalysis",
        "hit": bool(domains or hosts or compromised or urls or dns or procs or threat_tags or has_basic_info),
        "summary": summary_data,
        "threat_tags": threat_tags,
        "ioc": {
            "ips": (hosts + [h for h in compromised if h not in hosts])[:100],
            "domains": domains[:100],
            "urls": urls[:100],
        },
        "dns": dns[:100],
        "processes": procs[:100],
        "behavior": behavior_data,
        "detailed_test": {k: (v if isinstance(v, list) else v) for k, v in detailed.items()},
        "raw": js,
    }


def triage_lookup(hash_value: str, api_key: str) -> Dict[str, Any]:
    base = "https://api.tria.ge/v0"
    headers = {"accept": "application/json", "Authorization": f"Bearer {api_key}"}
    sid = None
    # å¦‚æœä¼ å…¥çš„å°±æ˜¯ Triage Sample IDï¼Œç›´æ¥ä½¿ç”¨
    if re.fullmatch(r"\d{6,}-[A-Za-z0-9]+", hash_value):
        sid = hash_value
    else:
        # å…ˆæœç´¢æ ·æœ¬ IDï¼ˆä½¿ç”¨ params é¿å…ç¼–ç é—®é¢˜ï¼‰
        try:
            rs = requests.get(f"{base}/search", params={"query": f"sha256:{hash_value}"}, headers=headers, timeout=30)
            js = rs.json() if rs.status_code == 200 else {"error": rs.text}
            try:
                save_json_data(hash_value, "triage_search", js)
            except Exception:
                pass
        except Exception as exc:
            return {"source": "Triage", "hit": False, "error": str(exc)}
        data = js.get("data") or []
        if not data:
            return {"source": "Triage", "hit": False}
        # é»˜è®¤é€‰æ‹©ç¬¬ä¸€ä¸ªï¼Œä¹Ÿå¯æ ¹æ®éœ€è¦æ›´æ¢ä¸ºéšæœºé€‰æ‹©
        sid = data[0].get("id")
    if not sid:
        return {"source": "Triage", "hit": False}
    # æ‹‰å–æ¦‚è¦/æŠ¥å‘Šï¼ˆå°½é‡è½»é‡ï¼‰
    try:
        rs2 = requests.get(f"{base}/samples/{sid}/summary", headers=headers, timeout=30)
        sumj = rs2.json() if rs2.status_code == 200 else {}
        try:
            save_json_data(hash_value, "triage_summary", sumj)
        except Exception:
            pass
    except Exception:
        sumj = {}
    # è¯¦ç»†ç«¯ç‚¹ï¼šnetworkã€behavior
    detailed: Dict[str, Any] = {}
    for endpoint in ("network", "behavior"):
        try:
            rr = requests.get(f"{base}/samples/{sid}/{endpoint}", headers=headers, timeout=30)
            if rr.status_code == 200:
                detailed[endpoint] = rr.json()
        except Exception:
            pass
    # ä» summary/analysis æå– IOC
    urls: List[str] = []
    ips: List[str] = []
    domains: List[str] = []
    procs: List[str] = []
    dns: List[str] = []
    # å…¼å®¹ä¸åŒå­—æ®µå‘½å
    for key in ("urls", "network_urls"):
        if isinstance(sumj.get(key), list):
            urls.extend(sumj.get(key) or [])
    for key in ("ips", "network_ips"):
        if isinstance(sumj.get(key), list):
            ips.extend(sumj.get(key) or [])
    if isinstance(sumj.get("dns"), list):
        for d in sumj.get("dns") or []:
            if isinstance(d, dict) and d.get("query"):
                dns.append(d.get("query"))
    if isinstance(sumj.get("processes"), list):
        for p in sumj.get("processes") or []:
            if isinstance(p, dict) and p.get("name"):
                procs.append(p.get("name"))
    # ä»è¯¦ç»†ç«¯ç‚¹è¡¥å……
    try:
        net = detailed.get("network") or {}
        urls.extend(net.get("urls", []) or [])
        ips.extend(net.get("ips", []) or [])
        if isinstance(net.get("dns"), list):
            for d in net.get("dns") or []:
                if isinstance(d, dict) and d.get("query"):
                    dns.append(d.get("query"))
    except Exception:
        pass
    try:
        beh = detailed.get("behavior") or {}
        for p in beh.get("processes", []) or []:
            if isinstance(p, dict) and p.get("name"):
                procs.append(p.get("name"))
    except Exception:
        pass
    # åŸŸåä» DNS ä¸­è¡¥å……
    domains.extend(dns)
    # å³ä½¿è¡Œä¸ºåˆ†æå¤±è´¥ï¼Œåªè¦æ‰¾åˆ°äº†æ ·æœ¬å°±ç®—å‘½ä¸­
    hit = bool(sid and sumj)
    
    return {
        "source": "Triage",
        "hit": hit,
        "summary": {
            "sample_id": sid,
            "filename": sumj.get("target", ""),
            "score": sumj.get("score", 0),
            "status": sumj.get("status", ""),
            "completed": sumj.get("completed", ""),
            "tasks": sumj.get("tasks", {})
        },
        "ioc": {"ips": list(dict.fromkeys(ips)), "domains": list(dict.fromkeys(domains)), "urls": list(dict.fromkeys(urls))},
        "dns": list(dict.fromkeys(dns))[:50],
        "processes": list(dict.fromkeys(procs))[:50],
        "detailed_test": {k: (v if isinstance(v, list) else v) for k, v in detailed.items()},
        "raw": sumj,
    }


def malshare_lookup(hash_value: str, api_key: str) -> Dict[str, Any]:
    """MalshareæŸ¥è¯¢å‡½æ•° - ä¸»è¦ç”¨äºæ£€æŸ¥æ ·æœ¬æ˜¯å¦å­˜åœ¨ï¼Œæ”¯æŒä¸‹è½½"""
    if not api_key:
        return {"source": "Malshare", "hit": False, "error": "No API key"}
    
    # é¦–å…ˆæ£€æŸ¥å†…å­˜ç¼“å­˜
    cached_data = get_cached_data_memory(hash_value, "malshare")
    if cached_data:
        print(f"ğŸ“¦ ä½¿ç”¨ Malshare ç¼“å­˜æ•°æ®")
        js = cached_data
    else:
        # æ²¡æœ‰ç¼“å­˜ï¼Œè¿›è¡Œ API æŸ¥è¯¢
        # ä½¿ç”¨getfile actionæ£€æŸ¥ç‰¹å®šhashæ˜¯å¦å­˜åœ¨ï¼Œè€Œä¸æ˜¯getlistï¼ˆé¿å…ç¼“å­˜å¤§é‡æ— ç”¨æ•°æ®ï¼‰
        base_url = "https://malshare.com/api.php"
        params = {
            "api_key": api_key,
            "action": "getfile",
            "hash": hash_value
        }
        
        try:
            r = requests.get(base_url, params=params, timeout=30)
            if r.status_code != 200:
                return {"source": "Malshare", "hit": False, "error": f"HTTP {r.status_code}"}
            
            # æ£€æŸ¥å“åº”å†…å®¹
            if b'Sample not found by hash' in r.content:
                # æ ·æœ¬ä¸å­˜åœ¨ï¼Œè¿”å›æœªå‘½ä¸­
                result = {"source": "Malshare", "hit": False, "raw": {"message": "Sample not found"}}
                save_json_data(hash_value, "malshare", result["raw"])
                return result
            else:
                # æ ·æœ¬å­˜åœ¨ï¼Œè¿”å›å‘½ä¸­ä¿¡æ¯
                result = {
                    "source": "Malshare", 
                    "hit": True, 
                    "summary": {
                        "å¯ä¸‹è½½": True,
                        "æ–‡ä»¶å¤§å°": f"{len(r.content)} bytes"
                    },
                    "raw": {"message": "Sample found", "downloadable": True},
                    "downloadable": True
                }
                save_json_data(hash_value, "malshare", result["raw"])
                return result
                
        except Exception as e:
            return {"source": "Malshare", "hit": False, "error": str(e)}
    
    # å¤„ç†ç¼“å­˜æ•°æ®
    if isinstance(js, dict):
        if js.get("message") == "Sample found":
            return {
                "source": "Malshare",
                "hit": True,
                "summary": {"å¯ä¸‹è½½": True},
                "raw": js,
                "downloadable": True
            }
        elif js.get("message") == "Sample not found":
            return {"source": "Malshare", "hit": False, "raw": js}
    
    return {"source": "Malshare", "hit": False, "raw": js}


def abuseipdb_check(ips: List[str], api_key: str) -> List[Dict[str, Any]]:
    results = []
    headers = {"Key": api_key, "Accept": "application/json"}
    for ip in ips:
        try:
            r = requests.get("https://api.abuseipdb.com/api/v2/check", params={"ipAddress": ip, "maxAgeInDays": 365}, headers=headers, timeout=20)
            if r.status_code == 200:
                results.append(r.json().get("data", {}))
        except Exception:
            continue
    return results


def resolve_domains_to_ips(domains: List[str]) -> List[str]:
    ips: List[str] = []
    for d in domains:
        try:
            ip = socket.gethostbyname(d)
            ips.append(ip)
        except Exception:
            pass
    return list(dict.fromkeys(ips))


def _merge_iocs(parts: List[Dict[str, Any]]) -> Dict[str, List[str]]:
    """æ±‡æ€»æ‰€æœ‰å¼•æ“çš„ IOC æ•°æ®ï¼Œåœ¨æ±‡æ€»å±‚è¿›è¡Œè¿‡æ»¤å’Œå»é‡"""
    ips: List[str] = []
    domains: List[str] = []
    urls: List[str] = []
    hashes: List[str] = []
    # ç¯å¢ƒå˜é‡å¼€å…³ï¼š
    #  - THUNTPRO_SHOW_ALL_URLS=1 æ—¶ï¼Œå…³é—­å¤§å‚åŸŸåè¿‡æ»¤ï¼Œå°½å¯èƒ½ä¿ç•™ URL
    #  - THUNTPRO_KEEP_DOMAINS=1 æ—¶ï¼Œç»“æœä¸­ä¿ç•™ domains å­—æ®µï¼ˆé»˜è®¤éšè—ï¼‰
    show_all_urls: bool = bool(os.environ.get("THUNTPRO_SHOW_ALL_URLS"))
    keep_domains: bool = bool(os.environ.get("THUNTPRO_KEEP_DOMAINS"))
    
    for r in parts:
        ioc = r.get("ioc") or {}
        # æ”¶é›†æ‰€æœ‰åŸå§‹ IOC æ•°æ®ï¼Œä¸åšè¿‡æ»¤
        ips.extend(ioc.get("ips") or [])
        domains.extend(ioc.get("domains") or [])
        urls.extend(ioc.get("urls") or [])
        hashes.extend(ioc.get("hashes") or [])
    
    # å®šä¹‰éœ€è¦è¿‡æ»¤çš„å¤§å‚åŸŸåï¼ˆä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼ï¼‰
    big_tech_patterns = [
        # Microsoft
        r'.*\.microsoft\.com$', r'.*\.windowsupdate\.com$', r'.*\.update\.microsoft\.com$',
        r'.*\.download\.windowsupdate\.com$', r'.*\.officecdn\.microsoft\.com$', r'.*\.msedge\.net$',
        r'.*\.live\.com$', r'.*\.outlook\.com$', r'.*\.outlook\.office365\.com$', r'.*\.onedrive\.com$',
        r'.*\.onedrive\.live\.com$', r'.*\.xboxlive\.com$', r'.*\.azure\.com$', r'.*\.azureedge\.net$',
        r'.*\.blob\.core\.windows\.net$', r'.*\.office\.com$', r'.*\.skype\.com$', r'.*\.skypeassets\.com$',
        r'.*\.teams\.microsoft\.com$',
        
        # Google / Alphabet
        r'.*\.google\.com$', r'.*\.gstatic\.com$', r'.*\.googleapis\.com$', r'.*\.googleusercontent\.com$',
        r'.*\.googlesyndication\.com$', r'.*\.gvt1\.com$', r'.*\.gvt2\.com$', r'.*\.android\.com$',
        r'.*\.firebaseio\.com$', r'.*\.doubleclick\.net$', r'.*\.youtube\.com$', r'.*\.ytimg\.com$',
        r'.*\.withgoogle\.com$', r'.*\.1e100\.net$', r'.*\.cloud\.google\.com$', r'.*\.gcp\.gvt2\.com$',
        
        # Apple
        r'.*\.apple\.com$', r'.*\.itunes\.com$', r'.*\.icloud\.com$', r'.*\.me\.com$',
        r'.*\.apple-cloudkit\.com$', r'.*\.mzstatic\.com$', r'.*\.akadns\.net$', r'.*\.edgesuite\.net$',
        
        # Amazon / AWS
        r'.*\.amazon\.com$', r'.*\.amazon\.co\.jp$', r'.*\.amazonaws\.com$', r'.*\.cloudfront\.net$',
        r'.*\.awstrack\.me$', r'.*\.awsdns-.*\.org$', r'.*\.awsdns-.*\.net$', r'.*\.awsdns-.*\.co\.uk$',
        r'.*\.a2z\.com$', r'.*\.primevideo\.com$', r'.*\.media-amazon\.com$', r'.*\.firebasestorage\.googleapis\.com$',
        
        # Meta (Facebook / Instagram / WhatsApp)
        r'.*\.facebook\.com$', r'.*\.fbcdn\.net$', r'.*\.fb\.com$', r'.*\.whatsapp\.com$', r'.*\.whatsapp\.net$',
        r'.*\.instagram\.com$', r'.*\.cdninstagram\.com$', r'.*\.messenger\.com$', r'.*\.fbsbx\.com$',
        
        # CDN æœåŠ¡å•†
        r'.*\.akamai\.net$', r'.*\.akamaiedge\.net$', r'.*\.akamaitechnologies\.com$', r'.*\.edgekey\.net$',
        r'.*\.cloudflare\.com$', r'.*\.cloudflare-dns\.com$', r'.*\.cloudflareinsights\.com$', r'.*\.cf-ipfs\.com$',
        r'.*\.crl\.cloudflare\.com$', r'.*\.fastly\.net$', r'.*\.fastlylb\.net$', r'.*\.global\.ssl\.fastly\.net$',
        r'.*\.fastlyjs\.com$', r'.*\.llnwd\.net$', r'.*\.limelight\.com$',
        
        # å…¶ä»–å¤§å‚
        r'.*\.oracle\.com$', r'.*\.java\.com$', r'.*\.sun\.com$', r'.*\.update\.oracle\.com$',
        r'.*\.adobe\.com$', r'.*\.adobe\.io$', r'.*\.adobelogin\.com$', r'.*\.adobesc\.com$', r'.*\.adobecc\.com$',
        r'.*\.ibm\.com$', r'.*\.redhat\.com$', r'.*\.rhsm\.redhat\.com$', r'.*\.fedoraproject\.org$', r'.*\.centos\.org$',
        r'.*\.cisco\.com$', r'.*\.webex\.com$', r'.*\.ciscodigital\.com$', r'.*\.duo\.com$',
        r'.*\.salesforce\.com$', r'.*\.force\.com$', r'.*\.salesforceliveagent\.com$', r'.*\.visual\.force\.com$',
        r'.*\.cdn77\.com$', r'.*\.cdn77\.org$', r'.*\.quic\.cloud$', r'.*\.litespeedtech\.com$',
        r'.*\.atlassian\.com$', r'.*\.jira\.com$', r'.*\.bitbucket\.org$', r'.*\.trello\.com$', r'.*\.statuspage\.io$',
        r'.*\.github\.com$', r'.*\.githubusercontent\.com$', r'.*\.githubassets\.com$', r'.*\.gitlab\.com$', r'.*\.gitlab\.io$',
        r'.*\.mozilla\.org$', r'.*\.firefox\.com$', r'.*\.ffxblue\.com$', r'.*\.addons\.mozilla\.org$', r'.*\.crash-stats\.mozilla\.com$',
        r'.*\.netflix\.com$', r'.*\.nflximg\.net$', r'.*\.nflxvideo\.net$', r'.*\.netflixdnstest\.com$',
        r'.*\.zoom\.us$', r'.*\.zoom\.com$', r'.*\.zoomgov\.com$', r'.*\.slack\.com$', r'.*\.slack-edge\.com$',
        
        # è½¯ä»¶ä»“åº“
        r'.*\.npmjs\.com$', r'.*\.npmjs\.org$', r'.*\.pypi\.org$', r'.*\.rubygems\.org$', r'.*\.maven\.org$', r'.*\.repo1\.maven\.org$',
        
        # ä¸­å›½å¤§å‚
        r'.*\.qq\.com$', r'.*\.weixin\.qq\.com$', r'.*\.wx\.qlogo\.cn$', r'.*\.wechat\.com$', r'.*\.qcloud\.com$',
        r'.*\.tencent\.com$', r'.*\.tencentcloud\.com$', r'.*\.gtimg\.com$', r'.*\.myqcloud\.com$', r'.*\.igamecj\.com$',
        r'.*\.alibaba\.com$', r'.*\.alicdn\.com$', r'.*\.aliyun\.com$', r'.*\.aliyuncs\.com$', r'.*\.taobao\.com$',
        r'.*\.tmall\.com$', r'.*\.tbcdn\.com$', r'.*\.mmstat\.com$', r'.*\.alipay\.com$', r'.*\.antfin\.com$',
        r'.*\.log\.aliyuncs\.com$', r'.*\.baidu\.com$', r'.*\.bdstatic\.com$', r'.*\.baidubcr\.com$', r'.*\.baidupcs\.com$',
        r'.*\.baidustatic\.com$', r'.*\.ers\.baidu\.com$', r'.*\.hm\.baidu\.com$', r'.*\.dueros\.baidu\.com$', r'.*\.a\.shifen\.com$',
        r'.*\.bytedance\.com$', r'.*\.toutiao\.com$', r'.*\.douyin\.com$', r'.*\.douyincdn\.com$', r'.*\.pstatp\.com$',
        r'.*\.snssdk\.com$', r'.*\.volcanoengine\.com$', r'.*\.huawei\.com$', r'.*\.huawei\.com\.cn$', r'.*\.huaweicloud\.com$',
        r'.*\.hwcdn\.net$', r'.*\.hicloud\.com$', r'.*\.update\.hicloud\.com$', r'.*\.mi\.com$', r'.*\.xiaomi\.com$',
        r'.*\.mi-img\.com$', r'.*\.miui\.com$', r'.*\.miuihuodong\.com$', r'.*\.xiaomicdn\.com$', r'.*\.163\.com$',
        r'.*\.126\.com$', r'.*\.127\.net$', r'.*\.163yun\.com$', r'.*\.music\.163\.com$', r'.*\.youdao\.com$',
        r'.*\.jd\.com$', r'.*\.jdcloud\.com$', r'.*\.jdpay\.com$', r'.*\.jdwl\.com$', r'.*\.360\.cn$',
        r'.*\.qihoo\.com$', r'.*\.so\.com$', r'.*\.360safe\.com$', r'.*\.360totalsecurity\.com$',
        r'.*\.bilibili\.com$', r'.*\.bilicdn1\.com$', r'.*\.hdslb\.com$', r'.*\.im9\.com$', r'.*\.sina\.com\.cn$',
        r'.*\.weibo\.com$', r'.*\.sinacdn\.com$', r'.*\.sinaimg\.cn$', r'.*\.iqiyi\.com$', r'.*\.71\.am\.com$',
        r'.*\.youku\.com$', r'.*\.aliyunccdn\.com$', r'.*\.hunantv\.com$', r'.*\.mgtv\.com$',
        
        # ç‰¹å®šåŸŸå
        r'^apache\.org$', r'^www\.apache\.org$', r'.*\.apache\.org$',
        r'^us-cert\.gov$', r'^www\.us-cert\.gov$', r'.*\.us-cert\.gov$',
        r'^exploit-db\.com$', r'^www\.exploit-db\.com$', r'.*\.exploit-db\.com$',
        r'^all\.bstring$',
        
        # å®‰å…¨å‚å•†
        r'.*\.symantec\.com$', r'.*\.symantecliveupdate\.com$', r'.*\.mcafee\.com$', r'.*\.mcafeeasap\.com$',
        r'.*\.kaspersky\.com$', r'.*\.kaspersky-labs\.com$', r'.*\.avast\.com$', r'.*\.trendmicro\.com$',
        r'.*\.sophos\.com$', r'.*\.eset\.com$', r'.*\.bitdefender\.com$', r'.*\.windowsdefender\.com$',
        
        # è¿è¥å•†å’Œ CDN
        r'.*\.chinanetcenter\.com$', r'.*\.chinacache\.net$', r'.*\.21vok00\.com$', r'.*\.chinaunicom\.com$',
        r'.*\.chinamobile\.com$', r'.*\.chinatelecom\.com\.cn$', r'.*\.cmvideo\.cn$', r'.*\.qiniu\.com$',
        r'.*\.qbox\.me$', r'.*\.upaiyun\.com$', r'.*\.ucloud\.cn$', r'.*\.ks-cdn\.com$', r'.*\.kingsoftcloud\.com$',
        
        # å¼€å‘è€…ç¤¾åŒº
        r'.*\.gitee\.com$', r'.*\.oschina\.net$', r'.*\.csdn\.net$', r'.*\.juejin\.cn$'
    ]
    
    # å°†åŸŸåè½¬æ¢ä¸º URL æ ¼å¼ï¼Œå¹¶è¿‡æ»¤å¤§å‚åŸŸå
    all_urls = []
    
    # å¤„ç†åŸå§‹ URLs
    for url in urls:
        # è¿‡æ»¤æ‰çº¯å“ˆå¸Œå€¼ï¼ˆ32-64ä½åå…­è¿›åˆ¶å­—ç¬¦ä¸²ï¼‰
        if not re.match(r"^[a-fA-F0-9]{32,64}$", url):
            # æå– URL ä¸­çš„åŸŸåè¿›è¡Œå¤§å‚åŸŸåè¿‡æ»¤
            if '://' in url:
                domain = url.split('://')[1].split('/')[0]
            else:
                domain = url.split('/')[0]
            
            domain_lower = domain.lower()
            is_big_tech = False
            
            if not show_all_urls:
                for pattern in big_tech_patterns:
                    if re.match(pattern, domain_lower):
                        is_big_tech = True
                        break
            
            if not is_big_tech:
                all_urls.append(url)
    
    # å¤„ç†åŸŸåï¼Œè½¬æ¢ä¸º URL æ ¼å¼
    for domain in domains:
        # è¿‡æ»¤å¤§å‚åŸŸåï¼ˆä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼ï¼‰
        domain_lower = domain.lower()
        is_big_tech = False
        
        if not show_all_urls:
            for pattern in big_tech_patterns:
                if re.match(pattern, domain_lower):
                    is_big_tech = True
                    break
        
        if not is_big_tech:
            # è¿‡æ»¤æ–‡ä»¶æ‰©å±•åå’Œæ— æ•ˆåŸŸå
            file_ext_re = r"\.(dll|pdb|exe|sys|drv|ocx|tlb|dat|bin|sdb|html|nls|mui)$"
            if not re.search(file_ext_re, domain_lower):
                # å°†åŸŸåè½¬æ¢ä¸º URL æ ¼å¼
                if not domain.startswith(('http://', 'https://')):
                    url_format = f"http://{domain}"
                else:
                    url_format = domain
                all_urls.append(url_format)
    
    return {
        "ips": list(dict.fromkeys(ips)),
        "domains": (list(dict.fromkeys(domains)) if keep_domains else []),  # é»˜è®¤éšè—ï¼Œå¯é€šè¿‡å¼€å…³ä¿ç•™
        "urls": list(dict.fromkeys(all_urls)),
        "hashes": list(dict.fromkeys(hashes)),
    }


def aggregate_hash(hash_value: str, apis: Dict[str, str]) -> Dict[str, Any]:
    out: Dict[str, Any] = {"hash": hash_value, "results": []}

    # å¹¶å‘æ‰§è¡Œæ”¯æŒ hash çš„å„å¼•æ“æŸ¥è¯¢ï¼ŒåŠ é€Ÿé¦–æ‰¹ç»“æœ
    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:
        future_to_source = {}
        vtapi = apis.get("VIRUSTOTAL") or ""
        if vtapi:
            future_to_source[executor.submit(vt_lookup, hash_value, vtapi)] = "VirusTotal"
        bazapi = apis.get("BAZAAR") or ""
        if bazapi:
            future_to_source[executor.submit(bazaar_lookup, hash_value, bazapi)] = "MalwareBazaar"
        avapi = apis.get("ALIENVAULT") or ""
        if avapi:
            future_to_source[executor.submit(alienvault_lookup, hash_value, avapi)] = "AlienVault"
        # InQuest åœç”¨
        haapi = apis.get("HYBRID-ANALYSIS") or apis.get("HYBRID") or apis.get("HAAPI") or apis.get("HYBRID_ANALYSIS") or ""
        if haapi:
            future_to_source[executor.submit(hybrid_lookup, hash_value, haapi)] = "HybridAnalysis"
        trapi = apis.get("TRIAGE") or ""
        if trapi:
            future_to_source[executor.submit(triage_lookup, hash_value, trapi)] = "Triage"
        msapi = apis.get("MALSHARE") or ""
        if msapi:
            future_to_source[executor.submit(malshare_lookup, hash_value, msapi)] = "Malshare"
        # ThreatBookï¼ˆhashï¼‰å¹¶å…¥å¹¶å‘
        tbapi = apis.get("THREATBOOK") or ""
        if tbapi:
            future_to_source[executor.submit(query_threatbook, hash_value, tbapi)] = "ThreatBook"

        for future in concurrent.futures.as_completed(future_to_source):
            try:
                res = future.result()
                if isinstance(res, dict):
                    # ThreatBook ç»“æœçš„ IOC æå–ï¼ˆä» summary ä¸­çš„ IOC_* å­—æ®µï¼‰
                    if res.get("source") == "ThreatBook" and res.get("hit") and res.get("summary"):
                        summary = res.get("summary") or {}
                        ioc_data = {}
                        for key, value in summary.items():
                            if isinstance(key, str) and key.startswith("IOC_"):
                                ioc_type = key.replace("IOC_", "").lower()
                                if isinstance(value, list):
                                    ioc_data[ioc_type] = value
                        if ioc_data:
                            res["ioc"] = ioc_data
                    out["results"].append(res)
            except Exception as e:
                src = future_to_source[future]
                out["results"].append({"source": src, "hit": False, "error": str(e)})
    # URLHaus æŸ¥è¯¢å·²åœç”¨
    # ThreatFoxï¼šä¸å†å¯¹åˆå¹¶IOCåšè¡¥å……æŸ¥è¯¢ï¼›ä»…åœ¨ç”¨æˆ·è¾“å…¥ä¸º IP / åŸŸå / URL æ—¶åœ¨ä¸Šå±‚åˆ†æ”¯è¿›è¡Œè°ƒç”¨

    # ä»…ä½¿ç”¨å„å¹³å°ç»“æ„åŒ–ç»“æœåˆå¹¶ IOCï¼Œé¿å…å¼•å…¥é IOC å™ªå£°
    merged = _merge_iocs(out["results"])
    out["ioc"] = merged

    abuse_key = apis.get("ABUSEIPDB") or ""
    if abuse_key and (out["ioc"].get("ips") or out["ioc"].get("domains")):
        all_ips = list(dict.fromkeys((out["ioc"].get("ips") or []) + resolve_domains_to_ips(out["ioc"].get("domains") or [])))
        client = AbuseIPDBClient(abuse_key)
        out["abuseipdb"] = client.batch_check(all_ips)
    # ä»…åŸºäºå®é™…æŸ¥è¯¢ç»“æœè¿›è¡Œå±•ç¤ºï¼Œä¸å†ä¸ºæœªæŸ¥è¯¢çš„å¼•æ“æ·»åŠ å ä½é¡¹
    # å‘½ä¸­ä¼˜å…ˆæ’åº
    out["results"] = sorted(out["results"], key=lambda r: (0 if r.get("hit") else 1, r.get("source")))
    return out

    

def enhanced_url_domain_query(indicator: str, apis: Dict[str, str]) -> Dict[str, Any]:
    """å¢å¼ºçš„ URL/åŸŸåæŸ¥è¯¢ï¼Œæå–å¨èƒæ ‡ç­¾ã€å­åŸŸåã€ç›¸å…³æ ·æœ¬ã€å†å²è§£æè®°å½•å’Œ Whois ä¿¡æ¯"""
    enhanced_data = {
        "threat_tags": [],
        "subdomains": [],
        "related_samples": [],
        "passive_dns": [],
        "whois_info": {}
    }
    
    # æå–åŸŸåï¼ˆå¦‚æœæ˜¯ URLï¼‰
    domain = indicator
    if indicator.startswith(('http://', 'https://')):
        try:
            from urllib.parse import urlparse
            parsed = urlparse(indicator)
            domain = parsed.hostname or indicator
        except Exception:
            pass
    
    # 1. å¨èƒæ ‡ç­¾æå– - ä» VirusTotal è·å–
    vtapi = apis.get("VIRUSTOTAL") or ""
    if vtapi:
        try:
            headers = {"x-apikey": vtapi}
            
            # è·å–åŸŸå/URL çš„è¯¦ç»†ä¿¡æ¯
            if indicator.startswith(('http://', 'https://')):
                # URL æŸ¥è¯¢
                url_id = requests.post("https://www.virustotal.com/api/v3/urls", 
                                     headers=headers, 
                                     data={"url": indicator}, 
                                     timeout=30).json().get("data", {}).get("id")
                if url_id:
                    url_data = requests.get(f"https://www.virustotal.com/api/v3/urls/{url_id}", 
                                          headers=headers, timeout=30).json()
                    attrs = url_data.get("data", {}).get("attributes", {})
                    
                    # æå–å¨èƒæ ‡ç­¾
                    if "last_analysis_results" in attrs:
                        for engine, result in attrs["last_analysis_results"].items():
                            if result.get("result") and result["result"] not in ["clean", "unrated"]:
                                enhanced_data["threat_tags"].append(f"{engine}: {result['result']}")
                    
                    # æå–ç›¸å…³æ ·æœ¬ (Files Referring)
                    files_url = f"https://www.virustotal.com/api/v3/urls/{url_id}/relationships/contacted_files"
                    files_resp = requests.get(files_url, headers=headers, timeout=30)
                    if files_resp.status_code == 200:
                        files_data = files_resp.json()
                        for file_item in files_data.get("data", [])[:20]:
                            file_id = file_item.get("id")
                            if file_id:
                                enhanced_data["related_samples"].append(file_id)
            else:
                # åŸŸåæŸ¥è¯¢
                domain_data = requests.get(f"https://www.virustotal.com/api/v3/domains/{domain}", 
                                         headers=headers, timeout=30)
                if domain_data.status_code == 200:
                    attrs = domain_data.json().get("data", {}).get("attributes", {})
                    
                    # æå–å¨èƒæ ‡ç­¾
                    if "last_analysis_results" in attrs:
                        for engine, result in attrs["last_analysis_results"].items():
                            if result.get("result") and result["result"] not in ["clean", "unrated"]:
                                enhanced_data["threat_tags"].append(f"{engine}: {result['result']}")
                    
                    # æå–å­åŸŸå (Siblings)
                    siblings_url = f"https://www.virustotal.com/api/v3/domains/{domain}/relationships/siblings"
                    siblings_resp = requests.get(siblings_url, headers=headers, timeout=30)
                    if siblings_resp.status_code == 200:
                        siblings_data = siblings_resp.json()
                        for sibling in siblings_data.get("data", []):
                            sibling_id = sibling.get("id")
                            if sibling_id:
                                enhanced_data["subdomains"].append(sibling_id)
                    
                    # æå–ç›¸å…³æ ·æœ¬
                    files_url = f"https://www.virustotal.com/api/v3/domains/{domain}/relationships/contacted_files"
                    files_resp = requests.get(files_url, headers=headers, timeout=30)
                    if files_resp.status_code == 200:
                        files_data = files_resp.json()
                        for file_item in files_data.get("data", [])[:20]:
                            file_id = file_item.get("id")
                            if file_id:
                                enhanced_data["related_samples"].append(file_id)
                    
                    # æå–å†å²è§£æè®°å½• (Passive DNS)
                    # ä½¿ç”¨å¸¦é‡è¯•ä¸å¯å…³é—­è¯ä¹¦æ ¡éªŒçš„ä¼šè¯è·å– Passive DNS
                    from requests.adapters import HTTPAdapter
                    from urllib3.util.retry import Retry
                    import requests as _rq
                    _session = _rq.Session()
                    _session.mount("https://", HTTPAdapter(max_retries=Retry(total=3, backoff_factor=0.5, status_forcelist=(429, 500, 502, 503, 504))))
                    _verify = os.environ.get("VT_VERIFY", "1") not in {"0", "false", "False"}
                    resolutions_url = f"https://www.virustotal.com/api/v3/domains/{domain}/relationships/resolutions"
                    resolutions_resp = _session.get(resolutions_url, headers=headers, timeout=30, verify=_verify)
                    if resolutions_resp.status_code == 200:
                        resolutions_data = resolutions_resp.json()
                        for resolution in resolutions_data.get("data", []):
                            ip = resolution.get("attributes", {}).get("ip_address")
                            date = resolution.get("attributes", {}).get("date")
                            if ip and date:
                                enhanced_data["passive_dns"].append(f"{ip} ({date})")
        except Exception as e:
            print(f"VirusTotal å¢å¼ºæŸ¥è¯¢é”™è¯¯: {e}")
    
    # 2. Whois ä¿¡æ¯æå– - æ”¹ä¸ºä» domains/{domain} attributes.whois ä¸­è§£æï¼Œæ”¯æŒ SSL å®¹é”™
    if vtapi and domain:
        try:
            headers = {"x-apikey": vtapi}
            from requests.adapters import HTTPAdapter
            from urllib3.util.retry import Retry
            import requests as _rq
            _session = _rq.Session()
            _session.mount("https://", HTTPAdapter(max_retries=Retry(total=3, backoff_factor=0.5, status_forcelist=(429, 500, 502, 503, 504))))
            _verify = os.environ.get("VT_VERIFY", "1") not in {"0", "false", "False"}
            d_r = _session.get(f"https://www.virustotal.com/api/v3/domains/{domain}", headers=headers, timeout=30, verify=_verify)
            if d_r.status_code == 200:
                attrs = (d_r.json().get("data") or {}).get("attributes") or {}
                whois_text = str(attrs.get("whois") or "")
                registrar = attrs.get("registrar")
                creation_date = attrs.get("creation_date")
                registrant_phone = None
                registrant_email = None
                if whois_text:
                    import re as _re
                    m = _re.search(r"Registrant Phone:\s*([^\r\n]+)", whois_text, _re.I)
                    if m:
                        registrant_phone = m.group(1).strip()
                    m = _re.search(r"Registrant Email:\s*([^\r\n]+)", whois_text, _re.I)
                    if m:
                        registrant_email = m.group(1).strip()
                enhanced_data["whois_info"] = {
                    "registrar": registrar,
                    "creation_date": creation_date,
                    "registrant_phone": registrant_phone,
                    "registrant_email": registrant_email,
                }
        except Exception as e:
            print(f"Whois æŸ¥è¯¢é”™è¯¯: {e}")
    
    # 3. ä» ThreatFox æå–å¨èƒæ ‡ç­¾
    tfapi = apis.get("THREATFOX") or ""
    if tfapi:
        try:
            tf_res = threatfox_multi_lookup(indicator, tfapi)
            if tf_res.get("hit") and tf_res.get("summary"):
                summary = tf_res["summary"]
                if summary.get("Threat Type"):
                    threat_type = summary["Threat Type"]
                    if isinstance(threat_type, list):
                        enhanced_data["threat_tags"].extend(threat_type)
                    else:
                        enhanced_data["threat_tags"].append(threat_type)
                
                if summary.get("Malware alias"):
                    alias = summary["Malware alias"]
                    if isinstance(alias, list):
                        enhanced_data["threat_tags"].extend(alias)
                    else:
                        enhanced_data["threat_tags"].append(alias)
        except Exception as e:
            print(f"ThreatFox å¨èƒæ ‡ç­¾æå–é”™è¯¯: {e}")
    
    # å»é‡å¨èƒæ ‡ç­¾
    enhanced_data["threat_tags"] = list(dict.fromkeys(enhanced_data["threat_tags"]))
    enhanced_data["subdomains"] = list(dict.fromkeys(enhanced_data["subdomains"]))
    enhanced_data["related_samples"] = list(dict.fromkeys(enhanced_data["related_samples"]))
    enhanced_data["passive_dns"] = list(dict.fromkeys(enhanced_data["passive_dns"]))
    
    return enhanced_data


def urlhaus_lookup(target: str, api_key: str) -> Dict[str, Any]:
    base = "https://urlhaus-api.abuse.ch/v1"
    s = requests.Session()
    headers = {"accept": "application/json"}
    if api_key:
        headers["Auth-Key"] = api_key
    s.headers.update(headers)
    data: Dict[str, Any] = {}
    hit = False
    urls: List[str] = []
    domains: List[str] = []
    summary: Dict[str, Any] = {}
    # URL æŸ¥è¯¢
    if re.match(r"^https?://", target, re.I):
        try:
            r = s.post(f"{base}/url/", data={"url": target}, timeout=30)
            js = r.json()
            hit = js.get("query_status") == "ok"
            if hit:
                data = js
                if js.get("host"):
                    domains.append(js.get("host"))
                urls.append(target)
                # æå–æ¦‚è¦
                summary = {
                    "URLçŠ¶æ€": js.get("url_status"),
                    "Host": js.get("host"),
                    "å¨èƒ": js.get("threat"),
                    "æ ‡ç­¾": js.get("tags"),
                    "æ·»åŠ æ—¶é—´": js.get("date_added"),
                    "å‚è€ƒ": js.get("urlhaus_reference"),
                }
                # å¯èƒ½å­˜åœ¨çš„ payload åˆ—è¡¨
                if isinstance(js.get("payloads"), list):
                    summary["æ ·æœ¬æ•°é‡"] = len(js.get("payloads"))
        except Exception:
            pass
    elif re.fullmatch(r"[A-Fa-f0-9]{32}", target) or re.fullmatch(r"[A-Fa-f0-9]{64}", target):
        # Hash æŸ¥è¯¢ï¼ˆpayload by hashï¼‰
        try:
            payload_data = {"md5_hash": target} if len(target) == 32 else {"sha256_hash": target}
            r = s.post(f"{base}/payload/", data=payload_data, timeout=30)
            js = r.json()
            hit = js.get("query_status") == "ok"
            if hit:
                data = js
                # å…³è” URLs
                for e in js.get("urls", []) or []:
                    u = e.get("url")
                    if u:
                        urls.append(u)
                        try:
                            from urllib.parse import urlparse
                            h = urlparse(u).hostname
                            if h:
                                domains.append(h)
                        except Exception:
                            pass
                summary = {
                    "æ–‡ä»¶ç±»å‹": js.get("file_type"),
                    "æ ·æœ¬å¤§å°": js.get("file_size"),
                    "é¦–æ¬¡è§åˆ°": js.get("firstseen"),
                    "æœ€åè§åˆ°": js.get("lastseen"),
                }
        except Exception:
            pass
    else:
        # host æŸ¥è¯¢
        try:
            r = s.post(f"{base}/host/", data={"host": target}, timeout=30)
            js = r.json()
            hit = js.get("query_status") == "ok"
            if hit:
                data = js
                count = 0
                for e in js.get("urls", []) or []:
                    u = e.get("url")
                    if u:
                        urls.append(u)
                        count += 1
                summary = {"å…³è”URLæ•°é‡": count}
        except Exception:
            pass
    return {
        "source": "URLHaus",
        "hit": bool(hit),
        "summary": summary if hit else {},
        "ioc": {"ips": [], "domains": list(dict.fromkeys(domains)), "urls": list(dict.fromkeys(urls))},
        "raw": data,
    }

def aggregate_indicator(indicator: str, apis: Dict[str, str]) -> Dict[str, Any]:
    # æ¸…ç©º tmp æ–‡ä»¶å¤¹
    clear_tmp_folder()
    
    out: Dict[str, Any] = {"indicator": indicator, "results": [], "apis": apis}
    # ThreatBook å¹¶è¡Œæ‰§è¡Œæ”¯æŒ
    tb_futures = []
    tb_executor = concurrent.futures.ThreadPoolExecutor(max_workers=5)
    is_hash = is_md5(indicator) or is_sha1(indicator) or is_sha256(indicator)
    is_ip = re.fullmatch(r"(?:(?:2(5[0-5]|[0-4]\\d))|(?:1?\\d?\\d))(?:\\.(?:(?:2(5[0-5]|[0-4]\\d))|(?:1?\\d?\\d))){3}", indicator) is not None
    is_url = re.match(r"^https?://", indicator, re.I) is not None

    # è¯†åˆ« ip:portï¼Œå¹¶å¹¶è¡ŒæŸ¥è¯¢ï¼šThreatFox ç”¨å®Œæ•´ ip:portï¼›å…¶ä½™å¼•æ“ç”¨çº¯ IPï¼›æŠ¥å‘ŠæŒ‡æ ‡æ˜¾ç¤ºä¸ºçº¯ IP
    m_ip_port = re.fullmatch(r"((?:(?:2(5[0-5]|[0-4]\\d))|(?:1?\\d?\\d))(?:\\.(?:(?:2(5[0-5]|[0-4]\\d))|(?:1?\\d?\\d))){3}):(\\d{1,5})", indicator)
    if m_ip_port:
        pure_ip = m_ip_port.group(1)
        port = m_ip_port.group(3)
        out["indicator"] = pure_ip
        # ThreatFox å°è¯•å®Œæ•´ ip:port ä¸çº¯ IP
        tfapi = apis.get("THREATFOX") or ""
        if tfapi:
            out["results"].append(threatfox_multi_lookup(indicator, tfapi))
            out["results"].append(threatfox_multi_lookup(pure_ip, tfapi))
        # å¯¹çº¯ IP èµ°åŸæœ‰ IP åˆ†æ”¯ï¼ˆVT/AlienVault/URLHausï¼‰
        vtapi = apis.get("VIRUSTOTAL") or ""
        if vtapi:
            try:
                headers = {"x-apikey": vtapi}
                urls: List[str] = []
                domains: List[str] = []
                # URLs å…³ç³»
                rr = requests.get(f"https://www.virustotal.com/api/v3/ip_addresses/{pure_ip}/relationships/urls", headers=headers, timeout=30)
                if rr.status_code == 200:
                    for it in rr.json().get("data", []) or []:
                        u = (it.get("attributes") or {}).get("url") or it.get("id")
                        if u:
                            urls.append(u)
                # è§£æåŸŸå resolutions å…³ç³»
                rr = requests.get(f"https://www.virustotal.com/api/v3/ip_addresses/{pure_ip}/relationships/resolutions", headers=headers, timeout=30)
                if rr.status_code == 200:
                    for it in rr.json().get("data", []) or []:
                        host_name = (it.get("attributes") or {}).get("host_name") or it.get("id")
                        if host_name:
                            domains.append(host_name)
                out["results"].append({"source": "VirusTotal", "hit": bool(urls or domains), "ioc": {"ips": [pure_ip], "domains": list(dict.fromkeys(domains)), "urls": list(dict.fromkeys(urls))}})
            except Exception:
                pass
        # AlienVault IP
        avapi = apis.get("ALIENVAULT") or ""
        if avapi:
            try:
                r = requests.get(f"https://otx.alienvault.com/api/v1/indicators/IPv4/{pure_ip}/general", headers={"X-OTX-API-KEY": avapi}, timeout=30)
                if r.status_code == 200:
                    js = r.json()
                    pulses = (js.get("pulse_info") or {}).get("pulses") or []
                    domains: List[str] = []
                    urls: List[str] = []
                    for p in pulses:
                        for ind in p.get("indicators", []) or []:
                            val = ind.get("indicator") or ""
                            t = (ind.get("type") or "").lower()
                            if t in {"domain", "hostname"}:
                                domains.append(val)
                            elif t in {"url", "uri"}:
                                urls.append(val)
                    out["results"].append({"source": "AlienVault", "hit": bool(pulses), "ioc": {"ips": [pure_ip], "domains": list(dict.fromkeys(domains)), "urls": list(dict.fromkeys(urls))}})
            except Exception:
                pass
        # URLHaus æŸ¥è¯¢å·²åœç”¨
        # åˆå¹¶ã€æ’åºå¹¶è¿”å›
        merged = _merge_iocs(out["results"])
        out["ioc"] = merged
        abuse_key = apis.get("ABUSEIPDB") or ""
        if abuse_key and (merged.get("ips") or merged.get("domains")):
            all_ips = list(dict.fromkeys((merged.get("ips") or []) + resolve_domains_to_ips(merged.get("domains") or [])))
            client = AbuseIPDBClient(abuse_key)
            out["abuseipdb"] = client.batch_check(all_ips)
        out["results"] = sorted(out["results"], key=lambda r: (0 if r.get("hit") else 1, r.get("source")))
        return out

    if is_hash:
        return aggregate_hash(indicator, apis)
    if is_url:
        # URLHaus æŸ¥è¯¢å·²åœç”¨
        # ThreatFox é’ˆå¯¹ URL çš„ host ä¹Ÿå°è¯•
        tfapi = apis.get("THREATFOX") or ""
        if tfapi:
            try:
                from urllib.parse import urlparse
                host = urlparse(indicator).hostname or ""
                if host:
                    tf_res = threatfox_multi_lookup(host, tfapi)
                    # è‹¥ ThreatFox æä¾› TriageIDsï¼Œä½¿ç”¨é…ç½®ä¸­çš„ TRIAGE key è§¦å‘ Triage æŸ¥è¯¢
                    if tf_res.get("hit"):
                        triage_ids = (tf_res.get("summary") or {}).get("TriageIDs") or []
                        if triage_ids:
                            tr_id = triage_ids[0]
                            tr_key = apis.get("TRIAGE") or apis.get("TRIAGEAPI") or ""
                            out["results"].append(triage_lookup(tr_id, tr_key))
                    out["results"].append(tf_res)
            except Exception:
                pass
        vtapi = apis.get("VIRUSTOTAL") or ""
        if vtapi:
            try:
                headers = {"x-apikey": vtapi}
                # æ­£ç¡®æ–¹å¼ï¼šå…ˆ POST /urls æäº¤ï¼Œå†ç”¨è¿”å›çš„ id æŸ¥è¯¢ï¼›è‹¥å¤±è´¥å›é€€åˆ° url_id è®¡ç®—
                rid = None
                try:
                    cr = requests.post("https://www.virustotal.com/api/v3/urls", data={"url": indicator}, headers=headers, timeout=30)
                    if cr.status_code == 200:
                        rid = (cr.json().get("data") or {}).get("id")
                except Exception:
                    rid = None
                if not rid:
                    try:
                        from utils.utils import compute_vt_url_id
                        rid = compute_vt_url_id(indicator)
                    except Exception:
                        rid = None
                urls: List[str] = [indicator]
                domains: List[str] = []
                ips: List[str] = []
                if rid:
                    # ä¸»æŠ¥å‘Šï¼ˆéå¿…é¡»ï¼‰
                    try:
                        _ = requests.get(f"https://www.virustotal.com/api/v3/urls/{rid}", headers=headers, timeout=30)
                    except Exception:
                        pass
                    # ä»…å°è¯•å¸¸è§å¯ç”¨çš„å…³ç³»ï¼Œ403/404 å¿½ç•¥
                    for rel in ("contacted_ips", "contacted_domains"):
                        try:
                            rr = requests.get(f"https://www.virustotal.com/api/v3/urls/{rid}/relationships/{rel}", headers=headers, timeout=30)
                            if rr.status_code == 200:
                                for it in rr.json().get("data", []) or []:
                                    if rel == "contacted_ips":
                                        ip = (it.get("attributes") or {}).get("ip_address") or it.get("id")
                                        if ip:
                                            ips.append(ip)
                                    else:
                                        dom = it.get("id")
                                        if dom:
                                            domains.append(dom)
                        except Exception:
                            pass
                out["results"].append({"source": "VirusTotal", "hit": bool(urls or domains or ips), "ioc": {"ips": list(dict.fromkeys(ips)), "domains": list(dict.fromkeys(domains)), "urls": list(dict.fromkeys(urls))}})
            except Exception:
                pass
        # åŒæ—¶å°è¯• host
        try:
            from urllib.parse import urlparse
            host = urlparse(indicator).hostname or ""
            if host:
                # URLHaus æŸ¥è¯¢å·²åœç”¨
                if tfapi:
                    out["results"].append(threatfox_multi_lookup(host, tfapi))
                # ThreatBookï¼šURL æŸ¥è¯¢ç¦ç”¨ï¼ˆæƒé™ä¸è¶³ï¼‰
        except Exception:
            pass
        
        # å¢å¼ºçš„ URL/åŸŸåæŸ¥è¯¢ - æå–å¨èƒæ ‡ç­¾ã€å­åŸŸåã€ç›¸å…³æ ·æœ¬ã€å†å²è§£æè®°å½•å’Œ Whois ä¿¡æ¯
        enhanced_data = enhanced_url_domain_query(indicator, apis)
        if any(enhanced_data.values()):
            out["enhanced"] = enhanced_data
    elif is_ip:
        vtapi = apis.get("VIRUSTOTAL") or ""
        if vtapi:
            try:
                headers = {"x-apikey": vtapi}
                urls: List[str] = []
                domains: List[str] = []
                # URLs å…³ç³»
                rr = requests.get(f"https://www.virustotal.com/api/v3/ip_addresses/{indicator}/relationships/urls", headers=headers, timeout=30)
                if rr.status_code == 200:
                    for it in rr.json().get("data", []) or []:
                        u = (it.get("attributes") or {}).get("url") or it.get("id")
                        if u:
                            urls.append(u)
                # è§£æåŸŸå resolutions å…³ç³»
                rr = requests.get(f"https://www.virustotal.com/api/v3/ip_addresses/{indicator}/relationships/resolutions", headers=headers, timeout=30)
                if rr.status_code == 200:
                    for it in rr.json().get("data", []) or []:
                        host_name = (it.get("attributes") or {}).get("host_name") or it.get("id")
                        if host_name:
                            domains.append(host_name)
                out["results"].append({"source": "VirusTotal", "hit": bool(urls or domains), "ioc": {"ips": [indicator], "domains": list(dict.fromkeys(domains)), "urls": list(dict.fromkeys(urls))}})
            except Exception:
                pass
        # AlienVault IP
        avapi = apis.get("ALIENVAULT") or ""
        if avapi:
            try:
                r = requests.get(f"https://otx.alienvault.com/api/v1/indicators/IPv4/{indicator}/general", headers={"X-OTX-API-KEY": avapi}, timeout=30)
                if r.status_code == 200:
                    js = r.json()
                    pulses = (js.get("pulse_info") or {}).get("pulses") or []
                    domains: List[str] = []
                    urls: List[str] = []
                    for p in pulses:
                        for ind in p.get("indicators", []) or []:
                            val = ind.get("indicator") or ""
                            t = (ind.get("type") or "").lower()
                            if t in {"domain", "hostname"}:
                                domains.append(val)
                            elif t in {"url", "uri"}:
                                urls.append(val)
                    out["results"].append({"source": "AlienVault", "hit": bool(pulses), "ioc": {"ips": [indicator], "domains": list(dict.fromkeys(domains)), "urls": list(dict.fromkeys(urls))}})
            except Exception:
                pass
        # URLHaus æŸ¥è¯¢å·²åœç”¨
        tfapi = apis.get("THREATFOX") or ""
        if tfapi:
            tf_res = threatfox_multi_lookup(indicator, tfapi)
            if tf_res.get("hit"):
                triage_ids = (tf_res.get("summary") or {}).get("TriageIDs") or []
                if triage_ids:
                    tr_id = triage_ids[0]
                    tr_key = apis.get("TRIAGE") or apis.get("TRIAGEAPI") or ""
                    out["results"].append(triage_lookup(tr_id, tr_key))
            out["results"].append(tf_res)
        # InQuest åœç”¨
        # ThreatBookï¼šIP æŸ¥è¯¢ä¿ç•™
        tbapi = apis.get("THREATBOOK") or ""
        if tbapi:
            tb_futures.append(tb_executor.submit(query_threatbook, indicator, tbapi))
    else:
        # ä½œä¸ºåŸŸåå¤„ç†
        # URLHaus æŸ¥è¯¢å·²åœç”¨
        tfapi = apis.get("THREATFOX") or ""
        if tfapi:
            tf_res = threatfox_multi_lookup(indicator, tfapi)
            if tf_res.get("hit"):
                triage_ids = (tf_res.get("summary") or {}).get("TriageIDs") or []
                if triage_ids:
                    tr_id = triage_ids[0]
                    tr_key = apis.get("TRIAGE") or apis.get("TRIAGEAPI") or ""
                    out["results"].append(triage_lookup(tr_id, tr_key))
            out["results"].append(tf_res)
        # InQuest åœç”¨
        # ThreatBookï¼šåŸŸåæŸ¥è¯¢ä¿ç•™
        tbapi = apis.get("THREATBOOK") or ""
        if tbapi:
            tb_futures.append(tb_executor.submit(query_threatbook, indicator, tbapi))
        # VT domain relationships
        vtapi = apis.get("VIRUSTOTAL") or ""
        if vtapi:
            try:
                headers = {"x-apikey": vtapi}
                domains: List[str] = [indicator]
                ips: List[str] = []
                urls: List[str] = []
                for rel in ("ip_addresses", "urls"):
                    rr = requests.get(f"https://www.virustotal.com/api/v3/domains/{indicator}/relationships/{rel}", headers=headers, timeout=30)
                    if rr.status_code == 200:
                        for it in rr.json().get("data", []) or []:
                            if rel == "ip_addresses":
                                ip = (it.get("attributes") or {}).get("ip_address") or it.get("id")
                                if ip:
                                    ips.append(ip)
                            else:
                                u = (it.get("attributes") or {}).get("url") or it.get("id")
                                if u:
                                    urls.append(u)
                out["results"].append({"source": "VirusTotal", "hit": bool(ips or urls), "ioc": {"ips": list(dict.fromkeys(ips)), "domains": domains, "urls": list(dict.fromkeys(urls))}})
            except Exception:
                pass
        # AlienVault domain general
        avapi = apis.get("ALIENVAULT") or ""
        if avapi:
            try:
                r = requests.get(f"https://otx.alienvault.com/api/v1/indicators/domain/{indicator}/general", headers={"X-OTX-API-KEY": avapi}, timeout=30)
                if r.status_code == 200:
                    js = r.json()
                    pulses = (js.get("pulse_info") or {}).get("pulses") or []
                    ips: List[str] = []
                    urls: List[str] = []
                    for p in pulses:
                        for ind in p.get("indicators", []) or []:
                            val = ind.get("indicator") or ""
                            t = (ind.get("type") or "").lower()
                            if t in {"ipv4", "ipv6", "ip"}:
                                ips.append(val)
                            elif t in {"url", "uri"}:
                                urls.append(val)
                    out["results"].append({"source": "AlienVault", "hit": bool(pulses), "ioc": {"ips": list(dict.fromkeys(ips)), "domains": [indicator], "urls": list(dict.fromkeys(urls))}})
            except Exception:
                pass
        
        # å¢å¼ºçš„ URL/åŸŸåæŸ¥è¯¢ - æå–å¨èƒæ ‡ç­¾ã€å­åŸŸåã€ç›¸å…³æ ·æœ¬ã€å†å²è§£æè®°å½•å’Œ Whois ä¿¡æ¯
        enhanced_data = enhanced_url_domain_query(indicator, apis)
        if any(enhanced_data.values()):
            out["enhanced"] = enhanced_data
    # æ”¶é›† ThreatBook futures ç»“æœ
    for f in concurrent.futures.as_completed(tb_futures):
        try:
            tb = f.result()
            if isinstance(tb, dict):
                out["results"].append(tb)
                # è‹¥å­˜åœ¨åŸå§‹æ•°æ®ï¼ŒæŒ‰åŸæœ‰è¡Œä¸ºä¿å­˜
                raw = tb.get("raw", {})
                if raw:
                    save_json_data(indicator, "threatbook", raw)
        except Exception as e:
            out["results"].append({"source": "ThreatBook", "hit": False, "error": str(e)})
    # å…³é—­æ‰§è¡Œå™¨
    tb_executor.shutdown(wait=False)

    merged = _merge_iocs(out["results"])
    out["ioc"] = merged
    abuse_key = apis.get("ABUSEIPDB") or ""
    if abuse_key and (merged.get("ips") or merged.get("domains")):
        all_ips = list(dict.fromkeys((merged.get("ips") or []) + resolve_domains_to_ips(merged.get("domains") or [])))
        client = AbuseIPDBClient(abuse_key)
        out["abuseipdb"] = client.batch_check(all_ips)
    # ç¡®ä¿æ‰€æœ‰å¼•æ“è‡³å°‘å ä½å‡ºç°
    present = {r.get("source") for r in out["results"]}
    for src in EXPECTED_SOURCES:
        if src not in present:
            out["results"].append({"source": src, "hit": False})
    out["results"] = sorted(out["results"], key=lambda r: (0 if r.get("hit") else 1, r.get("source")))
    return out


def print_chinese_report(agg: Dict[str, Any]) -> None:
    # å¯¼å…¥é¢œè‰²æ¨¡å—
    try:
        from colorama import Fore, Back, Style, init
        init(autoreset=True)
    except ImportError:
        # å¦‚æœæ²¡æœ‰ coloramaï¼Œä½¿ç”¨ ANSI é¢œè‰²ç 
        class Fore:
            RED = '\033[91m'
            GREEN = '\033[92m'
            YELLOW = '\033[93m'
            BLUE = '\033[94m'
            MAGENTA = '\033[95m'
            CYAN = '\033[96m'
            WHITE = '\033[97m'
        class Style:
            BRIGHT = '\033[1m'
            RESET_ALL = '\033[0m'
    
    # å…¥å£è„šæœ¬å·²æ‰“å°æ ‡é¢˜ä¸æ¨ªçº¿ï¼Œè¿™é‡Œä¸å†é‡å¤æ‰“å°æ ‡é¢˜ï¼Œé¿å…å†—ä½™
    print()
    
    if agg.get('hash'):
        print(f"{Fore.YELLOW}ğŸ” ç›®æ ‡å“ˆå¸Œ:{Style.RESET_ALL} {agg.get('hash')}")
    elif agg.get('indicator'):
        print(f"{Fore.YELLOW}ğŸ¯ ç›®æ ‡æŒ‡æ ‡:{Style.RESET_ALL} {agg.get('indicator')}")
    
    print(f"\n{Fore.BLUE}{Style.BRIGHT}ğŸ“Š æ£€æµ‹ç»“æœ:{Style.RESET_ALL}")
    results = agg.get("results", [])
    hit_results = [r for r in results if r.get("hit")]
    miss_results = [r for r in results if not r.get("hit")]

    # åˆ¤å®šæ¨¡å¼ï¼šhash / ip / url / domain
    ind = str(agg.get('hash') or agg.get('indicator') or '')
    ind_low = ind.lower()
    is_hash = bool(ind_low) and (len(ind_low) in (32, 40, 64)) and all(c in '0123456789abcdef' for c in ind_low)
    is_ip = bool(re.fullmatch(r"(?:(?:2(5[0-5]|[0-4]\\d))|(?:1?\\d?\\d))(?:\\.(?:(?:2(5[0-5]|[0-4]\\d))|(?:1?\\d?\\d))){3}", ind))
    is_url = bool(re.match(r"^https?://", ind, re.I))
    url_or_domain_mode = (not is_hash) and (not is_ip) and (is_url or ind)

    # å…ˆä»…æ‰“å°å‘½ä¸­æ‘˜è¦ï¼ˆæœªå‘½ä¸­ç§»è‡³æœ«å°¾ï¼‰
    for r in hit_results:
        src = r.get("source")
        print(f"{Fore.GREEN}âœ… {src}: å‘½ä¸­{Style.RESET_ALL}")

    # ç„¶åæ‰“å°"ç»¼åˆå‘½ä¸­ç»“æœ"åŒºå—ï¼ˆç»Ÿä¸€å­—æ®µå±•ç¤ºï¼‰
    if hit_results and not url_or_domain_mode:
        # æ±‡æ€»å­—æ®µ
        merged_threat_tags: List[str] = []
        merged_alias: List[str] = []
        merged_tags: List[str] = []
        merged_imports: List[str] = []
        filename = None
        family = None
        vt_stats = None

        for r in hit_results:
            _raw = r.get("raw") or {}
            summary = r.get("summary") or (_raw.get("summary") if isinstance(_raw, dict) else {}) or {}
            src = r.get("source")
            
            # å¤„ç† Triage çš„ç‰¹æ®Š summary ç»“æ„
            if src == "Triage":
                if not filename:
                    filename = summary.get("filename")
                if not family:
                    score = summary.get("score", 0)
                    if score > 0:
                        family = f"å¨èƒåˆ†æ•°: {score}"
                # Triage çš„å¨èƒæ ‡ç­¾å¯ä»¥ä» tasks ä¸­æå–
                tasks = summary.get("tasks", {})
                for task_id, task_info in tasks.items():
                    if isinstance(task_info, dict):
                        task_tags = task_info.get("tags", [])
                        if isinstance(task_tags, list):
                            merged_threat_tags.extend([str(x) for x in task_tags if x])
                        task_score = task_info.get("score", 0)
                        if task_score > 0:
                            merged_tags.append(f"{task_id}:{task_score}")
            else:
                # å…¶ä»–å¼•æ“çš„åŸæœ‰é€»è¾‘
                if not filename:
                    filename = summary.get("æ–‡ä»¶å") or summary.get("æ–‡ä»¶åç§°") or summary.get("submit_name")
                if not family:
                    family = summary.get("å®¶æ—/ç­¾å") or summary.get("å®¶æ—") or summary.get("ç­¾å") or summary.get("vx_family")
                ttags = summary.get("å¨èƒæ ‡ç­¾") or []
                if isinstance(ttags, list):
                    merged_threat_tags.extend([str(x) for x in ttags if x])
                elif ttags:
                    merged_threat_tags.append(str(ttags))
                tags = summary.get("æ ‡ç­¾") or summary.get("tags") or []
                if isinstance(tags, list):
                    merged_tags.extend([str(x) for x in tags if x])
                elif tags:
                    merged_tags.append(str(tags))
                alias = summary.get("æ ·æœ¬åˆ«å") or summary.get("åˆ«å") or []
                if isinstance(alias, list):
                    merged_alias.extend([str(x) for x in alias if x])
                elif alias:
                    merged_alias.append(str(alias))
                if not vt_stats and isinstance(summary.get("æ£€æµ‹ç»Ÿè®¡"), dict):
                    vt_stats = summary.get("æ£€æµ‹ç»Ÿè®¡")
                merged_imports.extend(summary.get("å¯¼å…¥å‡½æ•°") or [])

        # å»é‡
        merged_threat_tags = list(dict.fromkeys(merged_threat_tags))
        merged_tags = list(dict.fromkeys(merged_tags))
        merged_alias = list(dict.fromkeys(merged_alias))
        merged_imports = list(dict.fromkeys([str(x) for x in merged_imports]))

        # æ‰“å°ç»Ÿä¸€åŒºå—
        if merged_threat_tags:
            print(f"  ğŸ”¥ å¨èƒæ ‡ç­¾: {Fore.RED}{', '.join(merged_threat_tags)}{Style.RESET_ALL}")
        if filename:
            print(f"  ğŸ“„ æ–‡ä»¶å: {filename}")
        if family:
            print(f"  ğŸ§¬ å®¶æ—/ç­¾å: {family}")
        if merged_tags:
            print(f"  ğŸ·ï¸  æ ‡ç­¾: {', '.join(merged_tags)}")
        if vt_stats:
            stats_text = (
                f"æ¶æ„:{Fore.RED}{vt_stats.get('æ¶æ„', 0)}{Style.RESET_ALL} | "
                f"å¯ç–‘:{Fore.YELLOW}{vt_stats.get('å¯ç–‘', 0)}{Style.RESET_ALL} | "
                f"æ— å®³:{Fore.GREEN}{vt_stats.get('æ— å®³', 0)}{Style.RESET_ALL} | "
                f"æœªæ£€æµ‹:{Fore.CYAN}{vt_stats.get('æœªæ£€æµ‹', 0)}{Style.RESET_ALL}"
            )
            if vt_stats.get('å¤±è´¥', 0) > 0:
                stats_text += f" | å¤±è´¥:{Fore.MAGENTA}{vt_stats.get('å¤±è´¥', 0)}{Style.RESET_ALL}"
            print(f"  ğŸ“ˆ æ£€æµ‹ç»Ÿè®¡åˆ†æ: {stats_text}")
        if merged_alias:
            print(f"  ğŸ“‹ æ ·æœ¬åˆ«å: {', '.join(merged_alias)}")

        # å¨èƒåˆ†ç±»å‡½æ•°
        def classify_api(func_name: str) -> str:
            name = (func_name or "").lower()
            download_kw = ["url", "http", "internet", "wininet", "urlmon", "download", "winhttp", "recv", "send", "connect", "socket"]
            crypto_kw = ["crypt", "bcrypt", "aes", "rc4", "sha", "md5", "rsa"]
            system_kw = ["process", "thread", "toolhelp", "createthread", "openthread", "openprocess"]
            file_kw = ["createfile", "writefile", "readfile", "deletefile", "remove", "copyfile"]
            if any(k in name for k in download_kw):
                return "ç½‘ç»œè®¿é—®/ä¸‹è½½"
            if any(k in name for k in crypto_kw):
                return "åŠ å¯†/å“ˆå¸Œ"
            if any(k in name for k in system_kw):
                return "è¿›ç¨‹/çº¿ç¨‹æ“ä½œ"
            if any(k in name for k in file_kw):
                return "æ–‡ä»¶æ“ä½œ"
            return "å…¶å®ƒ"

        # é«˜å±å¯¼å…¥åˆ—è¡¨ï¼ˆåˆå¹¶åï¼‰
        high_risk_categories = {"ç½‘ç»œè®¿é—®/ä¸‹è½½", "åŠ å¯†/å“ˆå¸Œ"}
        high_risk_imports = []
        for fn in merged_imports:
            cls = classify_api(str(fn))
            if cls in high_risk_categories:
                high_risk_imports.append(str(fn))
        high_risk_imports = list(dict.fromkeys(high_risk_imports))
        # æŒ‰éœ€æ±‚ï¼šä¸éœ€è¦"å¯¼å…¥å‡½æ•°(é«˜å±)"å•ç‹¬åŒºå—ï¼Œä»…ä¿ç•™æŒ‰æ¨¡æ¿åˆ†ç»„å±•ç¤º

        # å¯¼å…¥å‡½æ•°åˆ†ç»„è¡¨ï¼ˆå¯¹é½å±•ç¤ºï¼Œåç§°ä¿æŒä¸º"å¯¼å…¥å‡½æ•°"ï¼‰â€”â€”æŒ‰ç”¨æˆ·æ¨¡æ¿åˆ†ç»„ï¼Œä»…æ˜¾ç¤ºå‘½ä¸­é¡¹
        if merged_imports:
            # åˆ†ç»„å…³é”®å­—
            # ä½¿ç”¨æœ‰åºåˆ†ç»„ï¼Œé¡ºåºä¸ç”¨æˆ·æ¨¡æ¿ä¸€è‡´
            bucket_items = [
                ("æ–‡ä»¶æ“ä½œå‡½æ•°", [
                    "CreateFile", "CreateFileA", "CreateFileW", "WriteFile", "ReadFile", "CopyFile", "MoveFile", "MoveFileEx", "MoveFileExA", "MoveFileExW", "DeleteFile", "DeleteFileA", "DeleteFileW",
                    "SetFileAttributes", "GetTempPath", "GetTempFileName", "SetFilePointer", "SetFilePointerEx", "GetFileSize", "GetFileType", "GetFileAttributes", "GetFileAttributesEx"
                ]),
                ("è¿›ç¨‹ä¸å†…å­˜æ“ä½œ", [
                    "VirtualAlloc", "VirtualAllocEx", "VirtualProtect", "VirtualProtectEx", "VirtualFree", "WriteProcessMemory", "ReadProcessMemory",
                    "CreateProcess", "CreateProcessA", "OpenProcess", "CreateRemoteThread", "GetProcAddress", "LoadLibrary",
                    "LoadLibraryA", "LoadLibraryW", "LoadLibraryExA", "LoadLibraryExW", "FreeLibrary", "GetModuleHandle", "GetModuleHandleA", "GetModuleHandleW",
                    "NtMapViewOfSection", "ZwUnmapViewOfSection", "RtlMoveMemory", "memcpy", "VirtualQuery", "VirtualQueryEx",
                    "CreateToolhelp32Snapshot", "Process32First", "Process32Next", "TerminateProcess", "SuspendThread", "ResumeThread",
                    "CreateFiber", "DeleteFiber", "SwitchToFiber", "ConvertThreadToFiber", "ConvertFiberToThread", "GetExitCodeThread",
                    "GetCurrentProcess", "GetCurrentProcessId", "GetCurrentThread", "GetCurrentThreadId"
                ]),
                ("æ³¨å†Œè¡¨æ“ä½œ", [
                    "RegCreateKey", "RegCreateKeyEx", "RegSetValue", "RegSetValueEx", "RegOpenKey", "RegOpenKeyEx",
                    "RegDeleteKey", "RegDeleteValue", "RegQueryValue", "RegQueryValueEx"
                ]),
                ("ç½‘ç»œå‡½æ•°", [
                    "WSAStartup", "socket", "connect", "bind", "listen", "accept", "send", "recv", "HttpOpenRequest",
                    "HttpSendRequest", "InternetOpen", "InternetOpenUrl", "InternetReadFile", "InternetWriteFile", "WinHttpOpen",
                    "WinHttpConnect", "WinHttpSendRequest", "WSAConnect"
                ]),
                ("ç³»ç»Ÿä¿¡æ¯ä¸é˜²å¾¡è§„é¿", [
                    "GetComputerName", "GetUserName", "IsDebuggerPresent", "CheckRemoteDebuggerPresent", "GetTickCount",
                    "QueryPerformanceCounter", "Sleep", "SleepEx", "SystemParametersInfo", "GetSystemInfo", "GetNativeSystemInfo", "GetWindowsDirectory",
                    "GetSystemDirectory", "GetSystemDirectoryA", "FindWindow", "FindWindowEx", "GetForegroundWindow", "SetWindowsHookEx",
                    "IsWow64Process", "GetVersionExA", "GetVersionExW", "OutputDebugStringA", "OutputDebugStringW",
                    "UnhandledExceptionFilter", "SetUnhandledExceptionFilter"
                ]),
                ("ä»£ç æ‰§è¡Œä¸æ³¨å…¥", [
                    "CreateThread", "NtCreateThreadEx", "QueueUserAPC", "RtlCreateUserThread", "ShellExecute", "ShellExecuteEx",
                    "WinExec", "system"
                ]),
                ("åŒæ­¥æœºåˆ¶", [
                    "CreateMutex", "CreateMutexW", "CreateEvent", "CreateEventW", "SetEvent", "ResetEvent",
                    "WaitForSingleObject", "WaitForSingleObjectEx", "WaitForMultipleObjects",
                    "InitializeCriticalSection", "EnterCriticalSection", "LeaveCriticalSection", "DeleteCriticalSection"
                ]),
                ("æ–‡ä»¶æ˜ å°„å‡½æ•°", [
                    "CreateFileMapping", "CreateFileMappingA", "CreateFileMappingW", "MapViewOfFile", "UnmapViewOfFile"
                ]),
                ("åŠ å¯†ä¸å“ˆå¸Œ", [
                    "CryptAcquireContext", "CryptCreateHash", "CryptHashData", "CryptEncrypt", "CryptDecrypt", "CryptGenRandom",
                    "BCrypt", "Cert"
                ]),
                ("æŒä¹…åŒ–ä¸è‡ªå¯åŠ¨", [
                    "SHGetSpecialFolderPath", "CreateService", "StartService", "ControlService", "OpenSCManager", "WMI"
                ]),
            ]
            buckets = {k: v for k, v in bucket_items}

            grouped: Dict[str, List[str]] = {k: [] for k in buckets.keys()}
            other_funcs: List[str] = []
            # å…ˆç”¨å·²æ±‡æ€»çš„å¯¼å…¥å‡½æ•°
            for raw in merged_imports:
                fn = str(raw)
                low = fn.lower()
                matched = False
                for cap, keys in buckets.items():
                    for kw in keys:
                        if kw.lower() in low:
                            grouped[cap].append(fn)
                            matched = True
                            break
                    if matched:
                        break
                if not matched:
                    other_funcs.append(fn)

            # å†ä»å››ä¸ªæºï¼ˆMalwareBazaar/VirusTotal/ThreatBook/AlienVaultï¼‰åŸå§‹æ•°æ®ä¸­é¢å¤–æŠ½å– API è¯æ®
            api_sources = {"MalwareBazaar", "VirusTotal", "ThreatBook", "AlienVault"}
            api_regex = re.compile(r"[A-Z0-9_]+\\.dll!?[:]{0,2}[A-Za-z0-9_]+")
            def is_high_risk(name: str) -> bool:
                n = name.lower()
                high_kw = [
                    "writeprocessmemory", "createremotethread", "virtualallocex", "ntwritevirtualmemory", "rtlmovememory",
                    "socket", "connect", "send", "recv", "internet", "winhttp", "wininet", "http",
                    "crypt", "bcrypt", "rsa", "aes", "md5", "sha"
                ]
                return any(k in n for k in high_kw)

            for r in hit_results:
                if r.get("source") not in api_sources:
                    continue
                try:
                    text_blob = json.dumps(r.get("raw") or r, ensure_ascii=False)
                except Exception:
                    continue
                for m in api_regex.findall(text_blob):
                    fn = m
                    low = fn.lower()
                    matched = False
                    for cap, keys in buckets.items():
                        for kw in keys:
                            if kw.lower() in low:
                                ev = fn + (" âš ï¸" if is_high_risk(fn) else "")
                                grouped[cap].append(ev)
                                matched = True
                                break
                        if matched:
                            break
                    if not matched:
                        other_funcs.append(fn)

            # æ‰“å°å¯¼å…¥å‡½æ•°åˆ†ç»„è¡¨
            print(f"\n{Fore.BLUE}{Style.BRIGHT}å¯¼å…¥å‡½æ•°:{Style.RESET_ALL}")
            
            def _print_category_row(title: str, evidences: List[str]):
                # æ— ä¸Šé™ï¼›ç©ºç»„éšè—
                ev = list(dict.fromkeys(evidences))
                if not ev:
                    return
                
                # ä½¿ç”¨å¤šåˆ—æ ¼å¼
                formatted_items = format_multi_column(ev, label_width=18)
                if '\n' in formatted_items:
                    # å¤šè¡Œæ˜¾ç¤º
                    lines = formatted_items.split('\n')
                    print(f"{title.ljust(18)}| {lines[0]}")
                    for line in lines[1:]:
                        print(f"{' '.ljust(18)}| {line}")
                else:
                    # å•è¡Œæ˜¾ç¤º
                    print(f"{title.ljust(18)}| {formatted_items}")

            for cap, _ in bucket_items:
                _print_category_row(cap, grouped.get(cap, []))

            # æŒ‰éœ€æ±‚ï¼šä»…æ˜¾ç¤ºå‘½ä¸­åˆ†ç±»ï¼Œä¸å±•ç¤ºæœªåŒ¹é…çš„"å…¶å®ƒ"å‡½æ•°

            # å¯¼å‡ºå‡½æ•°ï¼šä»å„æºæ±‡æ€»ï¼Œè‹¥æ— åˆ™ç•™ç©º
            merged_exports: List[str] = []
            for r in hit_results:
                # æ¥è‡ª summary
                _raw = r.get("raw") or {}
                summary = r.get("summary") or (_raw.get("summary") if isinstance(_raw, dict) else {}) or {}
                merged_exports.extend(summary.get("å¯¼å‡ºå‡½æ•°") or [])
                # æ¥è‡ª VirusTotal pe_info åŸå§‹ raw
                try:
                    raw = r.get("raw") or {}
                    pe_raw = (raw.get("data", {}) or {}).get("attributes", {}).get("pe_info") or raw.get("pe_info") or {}
                    for ex in pe_raw.get("exported_functions", []) or []:
                        if ex:
                            merged_exports.append(str(ex))
                except Exception:
                    pass
            merged_exports = list(dict.fromkeys([str(x) for x in merged_exports]))
            print(f"\n{Fore.BLUE}{Style.BRIGHT}å¯¼å‡ºå‡½æ•°:{Style.RESET_ALL}")
            if merged_exports:
                formatted_exports = format_multi_column(merged_exports, label_width=0, min_col_width=25)
                print(formatted_exports)
            else:
                print("  æ— å¯¼å‡ºå‡½æ•°")
            # æ¸…å•ï¼ˆå¯é€‰ï¼‰ï¼šä¸å†å•ç‹¬æ‰“å°æ—§æ¡†æ¶çš„ç®€å•æ¸…å•

        # å¤–éƒ¨æƒ…æŠ¥è¡¥å……ï¼ˆThreatFox / Triageï¼‰
        threatfox_result = next((rr for rr in hit_results if rr.get("source") == "ThreatFox"), None)
        if threatfox_result and isinstance(threatfox_result.get("summary"), dict):
            tf_sum = threatfox_result["summary"]
            extras = []
            if tf_sum.get("Threat Type"):
                val = tf_sum['Threat Type']
                extras.append(f"å¨èƒç±»å‹: {', '.join(val) if isinstance(val, list) else val}")
            if tf_sum.get("Malware alias"):
                val = tf_sum['Malware alias']
                extras.append(f"æ¶æ„å®¶æ—åˆ«å: {', '.join(val) if isinstance(val, list) else val}")
            if tf_sum.get("Confidence Level"):
                val = tf_sum['Confidence Level']
                extras.append(f"ç½®ä¿¡åº¦: {', '.join(val) if isinstance(val, list) else val}")
            if tf_sum.get("First seen"):
                extras.append(f"é¦–æ¬¡å‘ç°: {tf_sum['First seen']}")
            if tf_sum.get("Last seen"):
                extras.append(f"æœ€åå‘ç°: {tf_sum['Last seen']}")
            if tf_sum.get("Country"):
                val = tf_sum['Country']
                extras.append(f"å›½å®¶/åœ°åŒº: {', '.join(val) if isinstance(val, list) else val}")
            if tf_sum.get("Tags"):
                tags_val = tf_sum['Tags']
                # ä¸ VT æ¨¡ç‰ˆåŒºåˆ†æ˜¾ç¤º
                extras.append(f"ThreatFox_tag: {', '.join(tags_val) if isinstance(tags_val, list) else tags_val}")
            if tf_sum.get("Reference"):
                refs = tf_sum["Reference"] if isinstance(tf_sum["Reference"], list) else [tf_sum["Reference"]]
                extras.append(f"å‚è€ƒé“¾æ¥: {', '.join(refs)}")
                # è‡ªåŠ¨è§£æ Triage æ ·æœ¬IDå¹¶è§¦å‘ Triage æŸ¥è¯¢
                triage_ids = tf_sum.get("TriageIDs") or []
                if triage_ids:
                    # ä»…å–é¦–ä¸ªæ ·æœ¬IDè¿›è¡Œè¡¥å……
                    tr_id = triage_ids[0]
                    # å…è®¸åŒ¿åæŸ¥è¯¢å…¬å¼€æ ·æœ¬ï¼›è‹¥éœ€å¯†é’¥å¯é€šè¿‡ç¯å¢ƒå˜é‡ TRIAGEAPI æä¾›
                    trapi = os.environ.get('TRIAGEAPI', '')
                    tr_res = triage_lookup(tr_id, trapi)
                    if tr_res.get('hit'):
                        # å°† triage å‘½ä¸­ä¹Ÿè®¡å…¥ hit_results è¯­ä¹‰ï¼ˆç”¨äºæœ«å°¾æœªå‘½ä¸­åˆ—è¡¨æ­£ç¡®ç»Ÿè®¡ï¼‰
                        hit_results.append(tr_res)
                        # é™„å¸¦ç½‘ç»œè¿æ¥ï¼ˆåŒ…å«åè®®ï¼Œå°½é‡å±•ç¤º TCP/UDPï¼‰
                        net_ips = tr_res.get('ioc', {}).get('ips') or []
                        net_urls = tr_res.get('ioc', {}).get('urls') or []
                        if net_ips:
                            extras.append(f"Triage IP: {', '.join(net_ips[:10])}")
                        if net_urls:
                            extras.append(f"Triage URL: {', '.join(net_urls[:10])}")
            if extras:
                print(f"\n{Fore.CYAN}{Style.BRIGHT}ğŸŒ å¤–éƒ¨æƒ…æŠ¥è¡¥å……:{Style.RESET_ALL}")
                for line in extras:
                    print(f"  - {line}")

    # å±•ç¤ºä¸ VT ç›¸å…³çš„é¢å¤–å­—æ®µï¼ˆå¯¼å…¥/å¯¼å‡º/è½åœ°æ–‡ä»¶/è¿›ç¨‹æ ‘/è¡Œä¸ºæ•°æ®ï¼‰
    vt_result = next((rr for rr in hit_results if rr.get("source") == "VirusTotal"), None)
    if vt_result:
        if vt_result.get("dropped"):
            print(f"  ğŸ“ æ–‡ä»¶è½åœ°(å‰20): {vt_result['dropped']}")
        if vt_result.get("process_tree"):
            print("  ğŸŒ³ è¿›ç¨‹æ ‘(å‰5):", vt_result["process_tree"][:5])
        
        # æ˜¾ç¤ºè¡Œä¸ºæ•°æ®
        behavior = vt_result.get("behavior", {})
        if behavior:
            print(f"\n{Fore.MAGENTA}{Style.BRIGHT}ğŸ”¬ è¡Œä¸ºåˆ†æ:{Style.RESET_ALL}")
            
            def _print_behavior_section(icon: str, title: str, items: List[str]):
                if items:
                    formatted_items = format_multi_column(items[:15], label_width=18, min_col_width=25)
                    if '\n' in formatted_items:
                        lines = formatted_items.split('\n')
                        print(f"{icon} {title.ljust(16)}| {lines[0]}")
                        for line in lines[1:]:
                            print(f"{' '.ljust(18)}| {line}")
                    else:
                        print(f"{icon} {title.ljust(16)}| {formatted_items}")
            
            _print_behavior_section("ğŸ–¥ï¸", "Shellå‘½ä»¤", behavior.get("shell_commands", []))
            _print_behavior_section("â•", "åˆ›å»ºè¿›ç¨‹", behavior.get("processes_created", []))
            _print_behavior_section("â–", "ç»ˆæ­¢è¿›ç¨‹", behavior.get("processes_terminated", []))
            _print_behavior_section("ğŸ”§", "æ‰“å¼€æœåŠ¡", behavior.get("services_opened", []))
            _print_behavior_section("ğŸ“", "å†™å…¥æ–‡ä»¶", behavior.get("files_written", []))
            
            # æ˜¾ç¤ºè¿›ç¨‹æ ‘
            if vt_result.get("process_tree"):
                print(f"  ğŸŒ³ è¿›ç¨‹æ ‘:")
                for proc in vt_result["process_tree"][:5]:
                    pid = proc.get("pid", "N/A")
                    ppid = proc.get("ppid", "N/A")
                    name = proc.get("name", "Unknown")
                    print(f"    PID:{pid} PPID:{ppid} {name}")
    
    # è·å– Hybrid Analysis ç»“æœç”¨äºé£é™©è¯„ä¼°
    hybrid_result = next((rr for rr in hit_results if rr.get("source") == "HybridAnalysis"), None)
    
    # URL/åŸŸåæ¨¡å¼ï¼šç»Ÿä¸€æ¨¡æ¿å±•ç¤ºï¼ˆæŒ‰é¡ºåºï¼šæ ‡ç­¾â†’å­åŸŸâ†’ç›¸å…³æ ·æœ¬â†’å†å²è§£æâ†’Whoisï¼‰
    if url_or_domain_mode:
        # ä¼˜å…ˆä½¿ç”¨ VirusTotal çš„ summary å­—æ®µï¼Œå…¶æ¬¡å›é€€ enhanced
        vt_summary = {}
        for r in hit_results:
            try:
                if r.get("source") != "VirusTotal":
                    continue
                _raw = r.get("raw") or {}
                vt_summary = r.get("summary") or (_raw.get("summary") if isinstance(_raw, dict) else {}) or {}
                if vt_summary:
                    break
            except Exception:
                pass

        enh = agg.get("enhanced") or {}

        def _get_list(key: str, limit: int = 50) -> list:
            vals = []
            if isinstance(vt_summary, dict) and key in vt_summary:
                v = vt_summary.get(key) or []
                if isinstance(v, list):
                    vals = v
            if not vals and isinstance(enh, dict):
                mapping = {
                    "å¨èƒæ ‡ç­¾": enh.get("threat_tags"),
                    "å­åŸŸå": enh.get("subdomains"),
                    "ç›¸å…³æ ·æœ¬(å‰20)": enh.get("related_samples"),
                    "å†å²è§£æ/PassiveDNS": enh.get("passive_dns"),
                }
                v2 = mapping.get(key) or []
                if isinstance(v2, list):
                    vals = v2
            return list(dict.fromkeys([str(x) for x in (vals or [])]))[:limit]

        def _get_whois() -> dict:
            # ä»…é‡‡ç”¨ VirusTotal æä¾›çš„ Whois å­—æ®µ
            whois = {}
            if isinstance(vt_summary, dict):
                whois = vt_summary.get("Whois") or {}
            return {k: v for k, v in (whois or {}).items() if v}

        tags = _get_list("å¨èƒæ ‡ç­¾", 100)
        subs = _get_list("å­åŸŸå", 200)
        rels = _get_list("ç›¸å…³æ ·æœ¬(å‰20)", 20)
        pdns = _get_list("å†å²è§£æ/PassiveDNS", 200)
        whois = _get_whois()

        print(f"\n{Fore.CYAN}{Style.BRIGHT}ğŸ“š URL/åŸŸåæ¦‚è§ˆ:{Style.RESET_ALL}")
        if tags:
            formatted_tags = format_multi_column(tags[:30], label_width=18, min_col_width=25)
            if '\n' in formatted_tags:
                lines = formatted_tags.split('\n')
                print(f"  ğŸ”¥ {'å¨èƒæ ‡ç­¾'.ljust(16)}| {lines[0]}")
                for line in lines[1:]:
                    print(f"{' '.ljust(18)}| {line}")
            else:
                print(f"  ğŸ”¥ {'å¨èƒæ ‡ç­¾'.ljust(16)}| {formatted_tags}")
        else:
            print(f"  ğŸ”¥ {'å¨èƒæ ‡ç­¾'.ljust(16)}| -")
        if subs:
            formatted_subs = format_multi_column(subs[:50], label_width=18, min_col_width=25)
            if '\n' in formatted_subs:
                lines = formatted_subs.split('\n')
                print(f"  ğŸŒ {'å­åŸŸå(Siblings)'.ljust(16)}| {lines[0]}")
                for line in lines[1:]:
                    print(f"{' '.ljust(18)}| {line}")
            else:
                print(f"  ğŸŒ {'å­åŸŸå(Siblings)'.ljust(16)}| {formatted_subs}")
        else:
            print(f"  ğŸŒ {'å­åŸŸå(Siblings)'.ljust(16)}| -")
        if rels:
            formatted_rel = format_multi_column(rels[:20], label_width=18, min_col_width=25)
            if '\n' in formatted_rel:
                lines = formatted_rel.split('\n')
                print(f"  ğŸ§© {'ç›¸å…³æ ·æœ¬(å‰20)'.ljust(16)}| {lines[0]}")
                for line in lines[1:]:
                    print(f"{' '.ljust(18)}| {line}")
            else:
                print(f"  ğŸ§© {'ç›¸å…³æ ·æœ¬(å‰20)'.ljust(16)}| {formatted_rel}")
        else:
            print(f"  ğŸ§© {'ç›¸å…³æ ·æœ¬(å‰20)'.ljust(16)}| -")
        if pdns:
            formatted_dns = format_multi_column(pdns[:50], label_width=18, min_col_width=25)
            if '\n' in formatted_dns:
                lines = formatted_dns.split('\n')
                print(f"  ğŸ§­ {'å†å²è§£æ/PassiveDNS'.ljust(16)}| {lines[0]}")
                for line in lines[1:]:
                    print(f"{' '.ljust(18)}| {line}")
            else:
                print(f"  ğŸ§­ {'å†å²è§£æ/PassiveDNS'.ljust(16)}| {formatted_dns}")
        else:
            print(f"  ğŸ§­ {'å†å²è§£æ/PassiveDNS'.ljust(16)}| -")
        print("  ğŸ“‡ Whois:")
        print(f"    Registrar: {whois.get('Registrar') or '-'}")
        print(f"    Creation Date: {whois.get('Creation Date') or '-'}")
        if whois.get("Registrant Phone"):
            print(f"    æ³¨å†Œäººç”µè¯: {whois.get('Registrant Phone')}")
        else:
            print("    æ³¨å†Œäººç”µè¯: -")
        if whois.get("Registrant Email"):
            print(f"    æ³¨å†Œäººé‚®ç®±: {whois.get('Registrant Email')}")
        else:
            print("    æ³¨å†Œäººé‚®ç®±: -")
        # ç¬¬7é¡¹ï¼šè¯ä¹¦ä¿¡æ¯ï¼ˆè‹¥å­˜åœ¨ï¼‰
        try:
            cert = {}
            for r in hit_results:
                if r.get('source') == 'VirusTotal':
                    _raw = r.get('raw') or {}
                    summary_vt = r.get('summary') or (_raw.get('summary') if isinstance(_raw, dict) else {}) or {}
                    cert = summary_vt.get('è¯ä¹¦') or {}
                    if cert:
                        break
            print("  ğŸ” è¯ä¹¦:")
            if not cert:
                print("    -")
            else:
                if cert.get('subject_cn'):
                    print(f"    Subject CN: {cert.get('subject_cn')}")
                if cert.get('issuer'):
                    print(f"    Issuer: {cert.get('issuer')}")
                if cert.get('serial_number'):
                    print(f"    Serial: {cert.get('serial_number')}")
                if cert.get('fingerprint_sha256'):
                    print(f"    SHA256: {cert.get('fingerprint_sha256')}")
                if cert.get('valid_not_before'):
                    print(f"    Not Before: {cert.get('valid_not_before')}")
                if cert.get('valid_not_after'):
                    print(f"    Not After: {cert.get('valid_not_after')}")
        except Exception:
            pass

    # IOC ä¿¡æ¯æ˜¾ç¤ºï¼ˆè¿‡æ»¤ä¸å»é‡ï¼‰â€”â€”ä»…åœ¨å“ˆå¸Œä¸ IP æ¨¡å¼å±•ç¤ºï¼›URL/åŸŸåéšè—
    if agg.get("ioc", {}) and (is_hash or is_ip):
        ioc = agg.get("ioc", {})
        # è¿‡æ»¤å†…ç½‘å›ç¯ IP
        ips_filtered = [ip for ip in (ioc.get("ips") or []) if ip != "127.0.0.1"]
        # URL è¿‡æ»¤ï¼šå»é™¤åŒ…å« curl.se / index.php / example.com
        urls_raw = (ioc.get("urls") or [])
        urls_filtered = []
        for u in urls_raw:
            lu = u.lower()
            # è¿‡æ»¤æ˜æ˜¾é IOC çš„ç«™ç‚¹
            if ("curl.se" in lu) or ("example.com" in lu):
                continue
            # ä»…è¿‡æ»¤æ— ä¸»æœºçš„ä¼ª URLï¼šhttp://index.php æˆ– https://index.php
            try:
                if re.match(r"(?i)^https?://index\.php(?:[?#].*)?$", lu):
                    continue
            except Exception:
                pass
            urls_filtered.append(u)
        # å»é‡
        ips_filtered = list(dict.fromkeys(ips_filtered))
        urls_filtered = list(dict.fromkeys(urls_filtered))
        print(f"\n{Fore.GREEN}{Style.BRIGHT}ğŸ”— æå–åˆ°çš„ IOC:{Style.RESET_ALL}")
        if ips_filtered:
            print(f"  ğŸŒ {Fore.CYAN}IPåœ°å€:{Style.RESET_ALL} {', '.join(ips_filtered[:20])}")
        # æ— è®ºæ˜¯å¦ä¸ºç©ºï¼Œéƒ½æ‰“å° URL è¡Œï¼Œä¾¿äºç”¨æˆ·ç›´è§‚çœ‹åˆ°è¿‡æ»¤ç»“æœ
        url_text = ', '.join(urls_filtered[:20]) if urls_filtered else ''
        print(f"  ğŸ”— {Fore.MAGENTA}URL:{Style.RESET_ALL} {url_text}")
        if ioc.get("hashes"):
            print(f"  ğŸ” {Fore.RED}å“ˆå¸Œå€¼:{Style.RESET_ALL} {', '.join(ioc['hashes'][:10])}")
    
    # AbuseIPDB ä¿¡èª‰ä¿¡æ¯ï¼ˆè¿‡æ»¤ 127.0.0.1ï¼‰
    if agg.get("abuseipdb"):
        print(f"\n{Fore.YELLOW}{Style.BRIGHT}ğŸ›¡ï¸  IP ä¿¡èª‰è¯„ä¼°:{Style.RESET_ALL}")
        # åŠ¨æ€è°ƒæ•´æ˜¾ç¤ºæ•°é‡ï¼šè¶…è¿‡20ä¸ªIPæ˜¾ç¤ºtop20ï¼Œå¦åˆ™æ˜¾ç¤ºå…¨éƒ¨
        ip_count = len(agg["abuseipdb"])
        display_count = min(20, ip_count) if ip_count > 20 else ip_count
        
        for item in agg["abuseipdb"][:display_count]:
            ip = item.get("ipAddress")
            if ip == "127.0.0.1":
                continue
            score = item.get("abuseConfidenceScore")
            country = item.get("countryCode")
            total = item.get("totalReports")
            
            # ä¿®å¤ None å€¼æ¯”è¾ƒé”™è¯¯
            if score is None:
                score = 0
            if total is None:
                total = 0
            if country is None:
                country = "None"
            
            # æ ¹æ®ç½®ä¿¡åº¦é€‰æ‹©é¢œè‰²
            if score >= 75:
                score_color = Fore.RED
            elif score >= 25:
                score_color = Fore.YELLOW
            else:
                score_color = Fore.GREEN
            
            print(f"  ğŸ“ {ip} | ç½®ä¿¡åº¦: {score_color}{score}%{Style.RESET_ALL} | æŠ¥å‘Š: {total} | å›½å®¶: {country}")
    
    # æ ·æœ¬ä¸‹è½½ä¿¡æ¯ - åªæ˜¾ç¤ºçœŸæ­£æ”¯æŒä¸‹è½½çš„å¼•æ“
    downloadable_engines = []
    download_engine_map = {
        "Malshare": 1,
        "HybridAnalysis": 2, 
        "URLHaus": 3,
        "InQuest": 4,
        "VirusExchange": 5,
        "MalwareBazaar": 6
    }
    
    for result in hit_results:
        source = result.get("source")
        if source in download_engine_map:
            downloadable_engines.append(source)
    
    if downloadable_engines:
        print(f"\n{Fore.CYAN}{Style.BRIGHT}ğŸ“¥ æ ·æœ¬ä¸‹è½½:{Style.RESET_ALL}")
        download_info = []
        for engine in downloadable_engines:
            engine_num = download_engine_map[engine]
            if engine == "Malshare":
                download_info.append("Malshare 1")
            elif engine == "HybridAnalysis":
                download_info.append("HybridAnalysis 2")
            elif engine == "URLHaus":
                download_info.append("URLHaus 3")
            elif engine == "InQuest":
                download_info.append("InQuest 4")
            elif engine == "VirusExchange":
                download_info.append("VirusExchange 5")
            elif engine == "MalwareBazaar":
                download_info.append("MalwareBazaar 6")
        print(f"  ğŸ”½ å¯ä¸‹è½½å¼•æ“: {', '.join(download_info)}")
        # åˆ é™¤ä¸‹è½½å‘½ä»¤æç¤ºï¼Œä¿æŒè¾“å‡ºæ›´ç®€æ´

    # åœ¨ IP ä¿¡èª‰è¯„ä¼°ä¹‹åæ‰“å°æœªå‘½ä¸­å¼•æ“ï¼ˆå»é‡ï¼‰
    if miss_results:
        # å¯¹æœªå‘½ä¸­å¼•æ“è¿›è¡Œå»é‡
        unique_miss_sources = list(dict.fromkeys([r.get("source") for r in miss_results]))
        for src in unique_miss_sources:
            print(f"{Fore.RED}âŒ {src}: æœªå‘½ä¸­{Style.RESET_ALL}")

    # æ—§çš„ VirusTotal æ˜ç»†è¾“å‡ºåœ¨ URL/åŸŸåæ¨¡å¼ä¸‹å·²è¢«ä¸Šé¢çš„ç»Ÿä¸€æ¨¡æ¿æ›¿ä»£ï¼Œé¿å…é‡å¤


